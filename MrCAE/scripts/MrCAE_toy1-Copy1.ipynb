{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Model 1: 2 spatial modes with different oscillating frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created by Yuying Liu, 09/23/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Phi(x, t) = u(x)cos(\\omega_0 t) + v(x)cos(\\omega_1 t + \\frac{\\pi}{4})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import torch_cae_multilevel_V4 as net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "w0 = 0.5\n",
    "w1 = 4.0\n",
    "sigma0 = 10.0\n",
    "sigma1 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two modes\n",
    "def phi1(x, y, t):\n",
    "    return 1./np.cosh((x+1)/sigma0)/np.cosh((y-1)/sigma0)*np.cos(w0*t)\n",
    "\n",
    "def phi2(x, y, t):\n",
    "    return 1./(sigma1*np.sqrt(2*np.pi))*np.exp(-((x-1)**2+(y+1)**2)/(2*sigma1**2))*np.cos(w1*t + np.pi/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8058594381953778\n"
     ]
    }
   ],
   "source": [
    "# mesh grids\n",
    "x = np.linspace(-5, 5, 127)\n",
    "y = np.linspace(-5, 5, 127)\n",
    "t = np.linspace(0, 8*np.pi, 500)\n",
    "print((t[1]-t[0])*16)\n",
    "xgrid, ygrid, tgrid = np.meshgrid(x, y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 127, 500)\n",
      "(127, 127, 500)\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "Phi = phi1(xgrid, ygrid, tgrid) + phi2(xgrid, ygrid, tgrid)\n",
    "scaled_Phi = (Phi - Phi.min()) / (Phi.max() - Phi.min())\n",
    "print(Phi.shape)\n",
    "print(scaled_Phi.shape)\n",
    "\n",
    "# data_tuples = (Phi.T, t)\n",
    "# np.save(data_path, data_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MrCAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the progressive training framework. \n",
    "One could have flexible control over each training step: low-level models are cheap to obtain, and higher level models are built based on them -- one can always revert back to the previous level and adjust the parameters to re-train the model if it is not satisfying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init model & load data\n",
    "data_path = '../data/npy/toy1.npy'\n",
    "model_path = '../model/toy1_smaller'\n",
    "result_path = '../result/toy1_smaller/'\n",
    "\n",
    "np.save(data_path, Phi.T)\n",
    "\n",
    "dataset = net.MultiScaleDynamicsDataSet(data_path, n_levels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "Training = False\n",
    "if Training:\n",
    "    archs = [[1,2,3,4]]\n",
    "    tols = [0.001]#, 0.0005, 0.0001]\n",
    "    net.train_net(archs=archs, dataset=dataset, max_epoch=50, batch_size=350, \n",
    "                  tols=tols, activation=torch.nn.Sequential(), w=0.5, model_path=model_path, \n",
    "                  result_path=result_path, std=0.01, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model names: model_L{level}_{index}\n",
      "model_L0_0\n",
      "model_L0_1\n",
      "model_L0_2\n",
      "model_L0_3\n"
     ]
    }
   ],
   "source": [
    "# trained models at different levels\n",
    "models = {}\n",
    "print('model names: model_L{level}_{index}')\n",
    "for file_name in sorted(os.listdir(model_path)):\n",
    "    model_name, _ = file_name.split('.')\n",
    "    print(model_name)\n",
    "    models[model_name] = torch.load(os.path.join(model_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAE(\n",
      "  (activation): Sequential()\n",
      "  (L0_Conv_0): Conv2dBlock(\n",
      "    (activation): ReLU()\n",
      "    (B0): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      "  (L0_deConv_0): Conv2dBlock(\n",
      "    (activation): ReLU()\n",
      "    (B0): ConvTranspose2d(1, 1, kernel_size=(3, 3), stride=(2, 2))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(models['model_L0_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-bc29354c3401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_L0_3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataset_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiScaleDynamicsDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_levels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mvalid_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobtain_data_at_current_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mencoded0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - acornonsite.com\\Time_Space_multiscale\\MrCAE\\src\\utils.py\u001b[0m in \u001b[0;36mobtain_data_at_current_level\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# print(\"train_data shape = \", train_data.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_levels\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_local_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[1;31m# print(\"i = \", i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;31m# print(\"train_data shape = \", train_data.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - acornonsite.com\\Time_Space_multiscale\\MrCAE\\src\\utils.py\u001b[0m in \u001b[0;36mapply_local_op\u001b[1;34m(data, device, mode, ave)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "model0 = models['model_L0_3']\n",
    "dataset_graph = net.MultiScaleDynamicsDataSet(data_path, n_levels=20, train_ratio=1.0,  valid_ratio=0.0, shuffle = False)\n",
    "data,_,_ = dataset_graph.obtain_data_at_current_level(level=0)\n",
    "\n",
    "encoded0 = model0(data[:,:,:,:], model0.cur_level)\n",
    "encoded = encoded0\n",
    "# print(encoded.shape)\n",
    "# print(model0.resolved_maps['0']['0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "Model @Level 0:\n",
      "Perform deepening & widening, train each architectures ...\n",
      "num_of_channels =   1\n",
      "num_of_blocks =   1\n",
      "is_widen =   False\n",
      "mode =   conv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ghh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-bcb41a8b964e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiScaleDynamicsDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_levels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_net_one_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - acornonsite.com\\Time_Space_multiscale\\MrCAE\\src\\torch_cae_multilevel_V4.py\u001b[0m in \u001b[0;36mtrain_net_one_stage\u001b[1;34m(mode, n_filters, dataset, max_epoch, batch_size, result_path, load_model, tol, activation, lr, w, std, model_path, verbose)\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model @Level {}:'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur_level\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Perform deepening & widening, train each architectures ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeeper_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model layers: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - acornonsite.com\\Time_Space_multiscale\\MrCAE\\src\\torch_cae_multilevel_V4.py\u001b[0m in \u001b[0;36mdeeper_op\u001b[1;34m(self, std)\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[1;31m# the first layer at each level doesn't need nonlinearity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             self.add_module('L{}_Conv_{}'.format(self.cur_level, 0),\n\u001b[1;32m--> 301\u001b[1;33m                             Conv2dBlock(n_blocks, 1, mode='conv', is_widen=False, std=std))\n\u001b[0m\u001b[0;32m    302\u001b[0m             self.add_module('L{}_deConv_{}'.format(self.cur_level, 0),\n\u001b[0;32m    303\u001b[0m                             Conv2dBlock(1, 1, mode='deconv', is_widen=False, std=std))\n",
      "\u001b[1;32m~\\OneDrive - acornonsite.com\\Time_Space_multiscale\\MrCAE\\src\\torch_cae_multilevel_V4.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_of_blocks, num_of_channels, mode, is_widen, activation, std)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"is_widen =  \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_widen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode =  \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mghh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ghh' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = net.MultiScaleDynamicsDataSet(data_path, n_levels=20)\n",
    "net.train_net_one_stage(1, 2, dataset, 10, 500, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded.shape)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "a = encoded\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure( figsize=(8,8) )\n",
    "\n",
    "# a = snapshots[:,:,0]\n",
    "im = plt.imshow(a.detach().numpy()[0][0] , interpolation='none', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "def animate_func(i):\n",
    "    if i % fps == 0:\n",
    "        print( '.', end ='' )\n",
    "    im.set_array(a.detach().numpy()[i][0] )\n",
    "    return [im]\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "                               fig, \n",
    "                               animate_func, \n",
    "                               frames = int(nSeconds * fps),\n",
    "                               interval = 1000 / fps, # in ms\n",
    "                               )\n",
    "writergif = animation.PillowWriter(fps=30)\n",
    "anim.save('Toy_1_smaller_encoded_level0.gif', writer=writergif)#, fps=30)\n",
    "\n",
    "\n",
    "print('Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models['model_L0_1']\n",
    "dataset_graph = net.MultiScaleDynamicsDataSet(data_path, n_levels=0, train_ratio=1.0,  valid_ratio=0.0, shuffle = False)\n",
    "data,_,_ = dataset_graph.obtain_data_at_current_level(level=0)\n",
    "\n",
    "encoded1 = model1.encode(data[:,:,:,:], model1.cur_level)\n",
    "\n",
    "print(encoded1.shape)\n",
    "print(model1.resolved_maps['0']['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = model1.resolved_maps['0']['1'] - model0.resolved_maps['0']['0']\n",
    "plt.figure()\n",
    "plt.imshow(diff)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(encoded0[0,0, :,:].detach().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(encoded1[0,0, :,:].detach().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "dataset_graph = net.MultiScaleDynamicsDataSet(data_path, n_levels=3, train_ratio=1.0,  valid_ratio=0.0, shuffle = False)\n",
    "model = models['model_L0_0']\n",
    "\n",
    "# data = np.load(data_path)\n",
    "fps = 30\n",
    "# nSeconds = len(data) / fps\n",
    "\n",
    "# data = torch.tensor(data).unsqueeze(1).float()\n",
    "data,_,_ = dataset_graph.obtain_data_at_current_level(level=0)\n",
    "fps = 30\n",
    "nSeconds = len(data) / fps\n",
    "print(\"data shape = \", data.shape)\n",
    "print(\"model.cur_level = \", model.cur_level)\n",
    "a, _, _, _ = model(data[:,:,:,:], model.cur_level)\n",
    "a = data\n",
    "print(\"a shape = \", a.shape)\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure( figsize=(8,8) )\n",
    "\n",
    "# a = snapshots[:,:,0]\n",
    "im = plt.imshow(a.detach().numpy()[0][0] , interpolation='none', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "def animate_func(i):\n",
    "    if i % fps == 0:\n",
    "        print( '.', end ='' )\n",
    "    im.set_array(a.detach().numpy()[i][0] )\n",
    "    return [im]\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "                               fig, \n",
    "                               animate_func, \n",
    "                               frames = int(nSeconds * fps),\n",
    "                               interval = 1000 / fps, # in ms\n",
    "                               )\n",
    "writergif = animation.PillowWriter(fps=30)\n",
    "anim.save('Toy_1_smaller_Phi_predicted_level0.gif', writer=writergif)#, fps=30)\n",
    "\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the finest model\n",
    "# model = models['model_L2_3']\n",
    "model = models['model_L0_3']\n",
    "\n",
    "# resolved maps at different levels (that suggest poorly reconstructed regions)\n",
    "# for i in range(3):\n",
    "#     print(model.resolved_maps[str(i)].keys())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.pcolor(model.resolved_maps['0']['0'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "fig.savefig(os.path.join(result_path, 'L0_I0.png'))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.pcolor(model.resolved_maps['0']['1'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "fig.savefig(os.path.join(result_path, 'L0_I1.png'))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.pcolor(model.resolved_maps['0']['2'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "fig.savefig(os.path.join(result_path, 'L0_I2.png'))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.pcolor(model.resolved_maps['0']['3'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "fig.savefig(os.path.join(result_path, 'L0_I3.png'))\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "# ax.pcolor(model.resolved_maps['1']['0'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# fig.savefig(os.path.join(result_path, 'L1_I0.png'))\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "# ax.pcolor(model.resolved_maps['1']['1'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# fig.savefig(os.path.join(result_path, 'L1_I1.png'))\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "# ax.pcolor(model.resolved_maps['1']['2'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# fig.savefig(os.path.join(result_path, 'L1_I2.png'))\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "# ax.pcolor(model.resolved_maps['2']['0'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# fig.savefig(os.path.join(result_path, 'L2_I0.png'))\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "# ax.pcolor(model.resolved_maps['2']['1'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# fig.savefig(os.path.join(result_path, 'L2_I1.png'))\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "# ax.pcolor(model.resolved_maps['2']['2'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# fig.savefig(os.path.join(result_path, 'L2_I2.png'))\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "# ax.pcolor(model.resolved_maps['2']['3'].cpu().detach().numpy(), cmap='binary', vmin=0, vmax=1)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# fig.savefig(os.path.join(result_path, 'L2_I3.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructions of test snapshots\n",
    "\n",
    "inds = np.array(sorted(dataset.test_inds))\n",
    "dataset.test_inds = inds\n",
    "# print(len(dataset))\n",
    "n_snapshots = len(inds)\n",
    "n_samples = 6\n",
    "n_step = n_snapshots // 6\n",
    "\n",
    "fig, axes = plt.subplots(1, n_samples, figsize=(n_samples*11, 10))\n",
    "plt.subplots_adjust(wspace=0.01)\n",
    "for i in range(n_samples):\n",
    "    axes[i].pcolor(dataset.data[inds[i*n_step], :, :, :].squeeze().cpu().detach().numpy(), cmap='viridis')\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "fig.savefig(os.path.join(result_path, 'test_samples.png'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "model = models['model_L0_1']\n",
    "fig, axes = plt.subplots(1, n_samples, figsize=(n_samples*11, 10))\n",
    "plt.subplots_adjust(wspace=0.01)\n",
    "for i in range(n_samples):\n",
    "    _, _, data = dataset.obtain_data_at_current_level(level=0)\n",
    "    print(\"data[[i*n_step], :, :, :].shape = \", data[[i*n_step], :, :, :].shape)\n",
    "    print(model.cur_level)\n",
    "    output, _, _, _ = model(data[[i*n_step], :, :, :], model.cur_level)\n",
    "    print(output.shape)\n",
    "#     ghj\n",
    "    axes[i].pcolor(output.squeeze().cpu().detach().numpy(), cmap='viridis')\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "fig.savefig(os.path.join(result_path, 'test_L0_reconstructions.png'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "model = models['model_L1_2']\n",
    "fig, axes = plt.subplots(1, n_samples, figsize=(n_samples*11, 10))\n",
    "plt.subplots_adjust(wspace=0.01)\n",
    "for i in range(n_samples):\n",
    "    _, _, data = dataset.obtain_data_at_current_level(level=1)\n",
    "    print(\"data[[i*n_step], :, :, :].shape = \", data[[i*n_step], :, :, :].shape)\n",
    "    output, _, _, _ = model(data[[i*n_step], :, :, :], model.cur_level)\n",
    "    axes[i].pcolor(output.squeeze().cpu().detach().numpy(), cmap='viridis')\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "fig.savefig(os.path.join(result_path, 'test_L1_reconstructions.png'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "model = models['model_L2_3']\n",
    "fig, axes = plt.subplots(1, n_samples, figsize=(n_samples*11, 10))\n",
    "plt.subplots_adjust(wspace=0.01)\n",
    "for i in range(n_samples):\n",
    "    _, _, data = dataset.obtain_data_at_current_level(level=2)\n",
    "    print(\"data[[i*n_step], :, :, :].shape = \", data[[i*n_step], :, :, :].shape)\n",
    "    output, _, _, _ = model(data[[i*n_step], :, :, :], model.cur_level)\n",
    "    axes[i].pcolor(output.squeeze().cpu().detach().numpy(), cmap='viridis')\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "fig.savefig(os.path.join(result_path, 'test_L2_reconstructions.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig1, axes = plt.subplots(2, 1, figsize=(8, 16))\n",
    "axes[0].pcolor(xgrid[:,:,0], ygrid[:,:,0], phi1(xgrid, ygrid, tgrid)[:, :, 0].T, cmap='viridis')\n",
    "axes[1].pcolor(xgrid[:,:,0], ygrid[:,:,0], phi2(xgrid, ygrid, tgrid)[:, :, 0].T, cmap='viridis')\n",
    "\n",
    "axes[0].set_xticks([])\n",
    "axes[1].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "axes[1].set_yticks([])\n",
    "\n",
    "fig1.savefig(os.path.join(result_path, 'spatial_dynamics.png'))\n",
    "\n",
    "fig2, axes = plt.subplots(2, 1, figsize=(14*7, 24))\n",
    "axes[0].plot(t, np.cos(w0*t), t[inds[::n_step]], np.cos(w0*t[inds[::n_step]]), 'r.', linewidth=20, markersize=80)\n",
    "axes[1].plot(t, np.cos(w1*t + np.pi/4), t[inds[::n_step]], np.cos(w1*t[inds[::n_step]] + np.pi/4), 'r.', linewidth=20, markersize=80)\n",
    "#\n",
    "axes[0].set_xticks([])\n",
    "axes[1].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "axes[1].set_yticks([])\n",
    "\n",
    "fig2.savefig(os.path.join(result_path, 'temporal_dynamics.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {}\n",
    "for file_name in sorted(os.listdir(result_path)):\n",
    "    if file_name.endswith('.dat'):\n",
    "        key, _ = file_name.split('.')\n",
    "        with open(os.path.join(result_path, file_name), 'rb') as f: \n",
    "            records[key]= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_colors = 4\n",
    "colors = [(51/255, 51/255, 255/255)]+ \\\n",
    "         [(204/255, 153/255, 255/255), \n",
    "          (178/255, 102/255, 255/255),\n",
    "          (153/255, 51/255, 255/255),\n",
    "          (127/255, 0/255, 255/255),\n",
    "          (102/255, 0/255, 204/255),\n",
    "          (76/255, 0/255, 153/255)]\n",
    "\n",
    "fig1, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(80, 16))\n",
    "\n",
    "# plot\n",
    "s = 0\n",
    "for i in range(3):\n",
    "    level_errs = records['val_errs'][i]\n",
    "    n_widens = len(level_errs)\n",
    "    ax1.axvline(x=s, color='k', linestyle='--', linewidth=20)\n",
    "    for j in range(n_widens):\n",
    "        op_err = level_errs[j]\n",
    "        ax1.plot(range(s, s + len(op_err)), np.log(op_err), color=colors[j], linewidth=20)\n",
    "        s += len(op_err)\n",
    "        \n",
    "ax1.axvline(x=s-1, color='k', linestyle='--', linewidth=20)\n",
    "\n",
    "ax1.xaxis.set_tick_params(labelsize=100)\n",
    "ax1.yaxis.set_tick_params(labelsize=100)\n",
    "\n",
    "fig1.savefig(os.path.join(result_path, 'err_iter_plot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
