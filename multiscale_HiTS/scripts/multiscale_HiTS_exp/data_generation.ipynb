{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### created by Yuying Liu, 04/30/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used for generating data sets for multiscale HiTS experiments. Here, we consider 5 nonlinear systems: a hyperbolic fixed point, a damped cubic oscillator, the Van der Pol oscillator, a Hopf normal form, and the Lorenz system. Simulations are conducted using scipy.integrate.solve_ivp() and considered as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import integrate\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "data_dir = '../../data/'\n",
    "hyperbolic_dir = os.path.join(data_dir, 'Hyperbolic')\n",
    "cubic_dir = os.path.join(data_dir, 'Cubic')\n",
    "vdp_dir = os.path.join(data_dir, 'VanDerPol')\n",
    "hopf_dir = os.path.join(data_dir, 'Hopf')\n",
    "lorenz_dir = os.path.join(data_dir, 'Lorenz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustable parameters\n",
    "dt = 0.0005       # set to 5e-4 for Lorenz\n",
    "noise = 0.      # for study of noisy measurements, we use noise=0.01, 0.02; otherwise we leave it as 0.\n",
    "n_forward = 5\n",
    "total_steps = 1024 * n_forward\n",
    "t = np.linspace(0, (total_steps)*dt, total_steps+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperbolic fixed point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= \\mu x \\\\\n",
    "    \\dot{y} &= \\lambda(y-x^2)     \n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "mu = -0.05\n",
    "lam = -1.0\n",
    "def hyperbolic_rhs(x):\n",
    "    return np.array([mu*x[0], lam*(x[1]-x[0]**2)])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 2\n",
    "\n",
    "# dataset \n",
    "n_train = 1600\n",
    "n_val = 320\n",
    "n_test = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hyperbolic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hyperbolic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hyperbolic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(hyperbolic_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(hyperbolic_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(hyperbolic_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cubic oscillator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= -0.1x^3 + 2y^3 \\\\\n",
    "    \\dot{y} &= -2x^3 - 0.1y^3\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "def cubic_rhs(x):\n",
    "    return np.array([-0.1*x[0]**3+2*x[1]**3, \n",
    "                     -2*x[0]**3-0.1*x[1]**3])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 2\n",
    "\n",
    "# dataset \n",
    "n_train = 3200\n",
    "n_val = 320\n",
    "n_test = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: cubic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: cubic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: cubic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)    \n",
    "\n",
    "# save data\n",
    "np.save(os.path.join(cubic_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(cubic_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(cubic_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Van der Pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= y \\\\\n",
    "    \\dot{y} &= \\mu(1-x^2)y - x   \n",
    "\\end{split}\n",
    "\n",
    "where $\\mu=2.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "mu = 2.0\n",
    "def van_der_pol_rhs(x):\n",
    "    return np.array([x[1], mu*(1-x[0]**2)*x[1]-x[0]])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 2\n",
    "\n",
    "# dataset \n",
    "n_train = 3200\n",
    "n_val = 320\n",
    "n_test = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = [np.random.uniform(-2.0, 2.0), np.random.uniform(-4.0, 4.0)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: van_der_pol_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = [np.random.uniform(-2.0, 2.0), np.random.uniform(-2.0, 2.0)]    # make sure we have seen them in training set\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: van_der_pol_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = [np.random.uniform(-2.0, 2.0), np.random.uniform(-2.0, 2.0)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: van_der_pol_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "        \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(vdp_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(vdp_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(vdp_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopf bifurcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{\\mu} &= 0 \\\\\n",
    "    \\dot{x} &= \\mu x + y -x(x^2+y^2) \\\\\n",
    "    \\dot{y} &= \\mu y - x -y(x^2+y^2)\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "def hopf_rhs(x):\n",
    "    return np.array([0, x[0]*x[1]+x[2]-x[1]*(x[1]**2+x[2]**2),\n",
    "                    -x[1]+x[0]*x[2]-x[2]*(x[1]**2+x[2]**2)])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 3\n",
    "\n",
    "# dataset \n",
    "n_train = 3200\n",
    "n_val = 320\n",
    "n_test = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = [np.random.uniform(-0.2, 0.6), np.random.uniform(-1, 2), np.random.uniform(-1, 1)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hopf_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = [np.random.uniform(-0.2, 0.6), np.random.uniform(-1, 2), np.random.uniform(-1, 1)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hopf_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = [np.random.uniform(-0.2, 0.6), np.random.uniform(-1, 2), np.random.uniform(-1, 1)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hopf_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(hopf_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(hopf_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(hopf_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorenz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= \\sigma(y-x) \\\\\n",
    "    \\dot{y} &= x(\\rho-z)-y \\\\\n",
    "    \\dot{z} &= xy - \\beta z    \n",
    "\\end{split}\n",
    "\n",
    "where $\\sigma=10, \\rho=28, \\beta=8/3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "sigma = 10\n",
    "rho = 28\n",
    "beta = 8/3\n",
    "    \n",
    "def lorenz_rhs(x):\n",
    "    return np.array([sigma*(x[1]-x[0]), x[0]*(rho-x[2])-x[1], x[0]*x[1]-beta*x[2]])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "warmup = 10000\n",
    "n = 3\n",
    "\n",
    "# dataset \n",
    "n_train = 6400\n",
    "n_val = 640\n",
    "n_test = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating training trials ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a34876432484e4a8613a5a24fa5ebf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generating validation trials ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f84457481e445abb8b391b2437e156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=640.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generating testing trials ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e825add2fbf4a718053bd770beeabae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=640.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/Lorenz\\\\train_noise0.0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f6e0ca12e75f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# save data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlorenz_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_noise{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlorenz_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val_noise{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlorenz_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test_noise{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[0mfile_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/Lorenz\\\\train_noise0.0.npy'"
     ]
    }
   ],
   "source": [
    "# simulate training trials \n",
    "pre_t = np.linspace(0, warmup*dt, warmup+1)\n",
    "\n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "x_init = np.random.uniform(-0.1, 0.1, n)\n",
    "sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, warmup*dt], x_init, t_eval=pre_t)\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = sol.y[:, -1].T\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "x_init = np.random.uniform(-0.1, 0.1, n)\n",
    "sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, warmup*dt], x_init, t_eval=pre_t)\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = sol.y[:, -1].T    \n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "x_init = np.random.uniform(-0.1, 0.1, n)\n",
    "sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, warmup*dt], x_init, t_eval=pre_t)\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = sol.y[:, -1].T\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(lorenz_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(lorenz_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(lorenz_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/Lorenz\\\\train_noise0.0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2271d4898eec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlorenz_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_noise{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlorenz_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val_noise{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlorenz_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test_noise{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[0mfile_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/Lorenz\\\\train_noise0.0.npy'"
     ]
    }
   ],
   "source": [
    "np.save(os.path.join(lorenz_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(lorenz_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(lorenz_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
