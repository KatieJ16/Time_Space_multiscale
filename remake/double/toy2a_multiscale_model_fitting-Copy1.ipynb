{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiscale model fitting for Toy2a\n",
    "\n",
    "Toy2a is a simplified version of toy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start with initalizing many things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "# import sys\n",
    "import torch\n",
    "# import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm.notebook import tqdm\n",
    "# import time\n",
    "import math\n",
    "\n",
    "# module_path = os.path.abspath(os.path.join('../src/'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "    \n",
    "    \n",
    "# import torch_cae_multilevel_V4 as net\n",
    "import ResNet as tnet\n",
    "# import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "data_dir = '../data/toy2a'\n",
    "model_dir = '../models/toy2a'\n",
    "result_dir = '../result/toy2a'\n",
    "\n",
    "#load data\n",
    "train_data = torch.tensor(np.load(os.path.join(data_dir, 'train_data.npy')))\n",
    "val_data = torch.tensor(np.load(os.path.join(data_dir, 'val_data.npy')))\n",
    "test_data = torch.tensor(np.load(os.path.join(data_dir, 'test_data.npy')))\n",
    "\n",
    "data_of_sizes = {}\n",
    "current_size = 2\n",
    "unresolved_dict = {}\n",
    "model_keep = list()\n",
    "model_used_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_size =  32\n",
      "x_end_idx =  33\n",
      "y_start_idx =  64\n",
      "y_end_idx =  225\n",
      "range(0, 33, 32)\n",
      "self.train_x shape =  torch.Size([100, 128])\n",
      "train_ys shape =  torch.Size([100, 6, 64])\n"
     ]
    }
   ],
   "source": [
    "#testing dataset new structure\n",
    "dt = 1\n",
    "step_size = 32\n",
    "n_forward = 5\n",
    "dataset = tnet.DataSet(torch.flatten(train_data,2,3), torch.flatten(val_data,2,3), torch.flatten(test_data,2,3), dt, step_size, n_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 6, 64])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.train_ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions, will move these to a utils file eventually \n",
    "#====================================================================================\n",
    "# def data_of_size(data,size):\n",
    "#     \"\"\"\n",
    "#     Takes averages to shrink size of data\n",
    "#     Takes data of size (n_points, dim, dim) and shrinks to size (n_points, size, size)\n",
    "#     takes averages to shrink\n",
    "#     \"\"\"\n",
    "#     return decrease_to_size(torch.tensor(data).unsqueeze(1), size)[:,0,:,:]\n",
    "#====================================================================================\n",
    "\n",
    "\n",
    "def isPowerOfTwo(n):\n",
    "    \"\"\"\n",
    "    checks if n is a power of two\n",
    "    \n",
    "    input: n, int\n",
    "    \n",
    "    output: boolean\n",
    "    \"\"\"\n",
    "    return (np.ceil(np.log2(n)) == np.floor(np.log2(n)));\n",
    "#====================================================================================\n",
    "def shrink(data, low_dim):\n",
    "    '''\n",
    "    Shrinks data to certain size; either averages or takes endpoints\n",
    "    \n",
    "    inputs:\n",
    "        data: array of size (n_points, n_timesteps, dim, dim) that will shrink\n",
    "        low_dim: int, size to shrink to, low_dim must be less than or equal to dim\n",
    "        \n",
    "    output:\n",
    "        data: array of size (n_points, n_timesteps, low_dim, low_dim)\n",
    "    '''\n",
    "    \n",
    "    #check inputs\n",
    "    assert len(data.shape) == 4\n",
    "    n_points, n_timesteps, dim, _ = data.shape\n",
    "    assert dim >= low_dim\n",
    "    assert isPowerOfTwo(low_dim)\n",
    "    \n",
    "    if dim == low_dim: #same size, no change\n",
    "        return data\n",
    "    \n",
    "    while(dim > low_dim):\n",
    "        #shrink by 1 level until same size\n",
    "        data = apply_local_op(data.float(), 'cpu', ave=average)\n",
    "        current_size = data.shape[-1]\n",
    "        \n",
    "    return data\n",
    "#====================================================================================\n",
    "def ave_one_level(data):\n",
    "    '''\n",
    "    takes averages to shrink data 1 level\n",
    "    \n",
    "    inputs:\n",
    "        data: tensor of size (n_points, n_timesteps, dim, dim) that will shrink\n",
    "        \n",
    "    output:\n",
    "        processed data: tensor of size (n_points, n_timesteps, dim/2, dim/2)\n",
    "    '''\n",
    "    device = 'cpu'\n",
    "    if not torch.is_tensor(data): #needs to be a tensor\n",
    "        data = torch.tensor(data)\n",
    "        \n",
    "    assert len(data.shape) == 4\n",
    "#     if data.shape != 4:\n",
    "#         print(\"data.shape = \", data.shape)\n",
    "#         print(\"data.shape should be of length 4\")\n",
    "    n_points, n_timesteps, dim, _ = data.shape\n",
    "    \n",
    "    #dim needs to be even \n",
    "    assert dim % 2 == 0\n",
    "    \n",
    "    data_right_size = torch.flatten(data, 0,1).unsqueeze(1).float()\n",
    "    \n",
    "#     n = min(in_channels, out_channels)\n",
    "    op = torch.nn.Conv2d(1, 1, 2, stride=2, padding=0).to(device)\n",
    "   \n",
    "    op.weight.data = torch.zeros(op.weight.data.size()).to(device)\n",
    "    op.bias.data = torch.zeros(op.bias.data.size()).to(device)\n",
    "    op.weight.data[0,0, :, :] = torch.ones(op.weight.data[0,0, :, :].size()).to(device) / 4\n",
    "\n",
    "    # make them non-trainable\n",
    "    for param in op.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    print(\"Transforming\")\n",
    "        \n",
    "    shrunk = op(data_right_size)\n",
    "    \n",
    "    print(\"reshape to print\")\n",
    "    \n",
    "    return shrunk.squeeze(1).reshape((n_points, n_timesteps, dim//2, dim//2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data.shape)\n",
    "# processed = ave_one_level(train_data)\n",
    "# print(processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make a dictionary with train data of every size 128->1\n",
    "#====================================================================================\n",
    "\n",
    "def make_dict_all_sizes(data):\n",
    "    \"\"\"\n",
    "    Makes a dictionary of data at every refinedment size from current->1\n",
    "    \n",
    "    inputs:\n",
    "        data: tensor(or array) of size (n_points, n_timesteps, dim, dim)\n",
    "        \n",
    "    outputs: \n",
    "        dic: dictionary of tensors. Keys are dim size, tensors are size (n_points, n_timesteps, dim, dim)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_points, n_timesteps, dim, _ = data.shape\n",
    "    \n",
    "    if not torch.is_tensor(data): #needs to be a tensor\n",
    "        data = torch.tensor(data)\n",
    "        \n",
    "    assert isPowerOfTwo(dim)\n",
    "        \n",
    "    dic = {str(dim): data}\n",
    "    \n",
    "    for i in range(int(np.log2(dim))):\n",
    "        #decrease\n",
    "        print(\"i = \", i)\n",
    "        data = ave_one_level(data)\n",
    "        dic[str(data.shape[-1])] = data\n",
    "    \n",
    "    print(dic.keys())\n",
    "    \n",
    "    return dic\n",
    "#====================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  1\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  2\n",
      "Transforming\n",
      "reshape to print\n",
      "dict_keys(['8', '4', '2', '1'])\n",
      "i =  0\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  1\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  2\n",
      "Transforming\n",
      "reshape to print\n",
      "dict_keys(['8', '4', '2', '1'])\n"
     ]
    }
   ],
   "source": [
    "train_dict = make_dict_all_sizes(train_data)\n",
    "val_dict = make_dict_all_sizes(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([499, 1])\n",
      "torch.Size([499, 1])\n"
     ]
    }
   ],
   "source": [
    "train_x = train_dict['1'][0,:-1,0]\n",
    "print(train_x.shape)\n",
    "train_y = train_dict['1'][0,1:,0]\n",
    "print(train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ResNet as tnet\n",
    "#====================================================================================\n",
    "def train_one_timestep(step_size, train_data, val_data=None, test_data=None, current_size=1, \n",
    "                       dt = 1, n_forward = 5, noise=0, make_new = False, dont_train = True, \n",
    "                       lr = 1e-3, max_epochs = 10000, batch_size = 50,threshold = 1e-4, \n",
    "                       model_dir = './models/toy2',i=None, j = None,print_every=1000):\n",
    "\n",
    "    \"\"\"\n",
    "    fits or loads model at 1 timestep\n",
    "    \n",
    "    inputs:\n",
    "        step_size: int \n",
    "        train_data: tensor size (n_points, n_timesteps, dim**2) \n",
    "        val_data:tensor size (n_val_points, n_timesteps, dim**2) \n",
    "        test_data:tensor size (n_test_points, n_timesteps, dim**2) \n",
    "        current_size: int, only used in file naming\n",
    "        dt = 1: float\n",
    "        n_forward = 5: int, number of steps to consider during training\n",
    "        noise=0: float, level of noise, (right now just used in file naming)\n",
    "        make_new = False: boolean, whether or not to make a new model if old already exists\n",
    "        dont_train = True: boolean, whether or not to train more if model loaded\n",
    "        lr = 1e-3: float, learning rate\n",
    "        max_epochs = 10000: int \n",
    "        batch_size = 50: int\n",
    "        threshold=1e-4: float, stop training when validation gets below threshold\n",
    "         \n",
    "    \n",
    "    outputs:\n",
    "        model_time: ResNet object of trained model. Also saved\n",
    "    \"\"\"\n",
    "    print(\"inside train_one_timestep\")\n",
    "    if (i is not None) and (j is not None):\n",
    "        \n",
    "        model_name = 'model_L{}_D{}_noise{}_i{}_j{}.pt'.format(current_size,step_size, noise, i, j)\n",
    "    else:\n",
    "        model_name = 'model_L{}_D{}_noise{}.pt'.format(current_size,step_size, noise)\n",
    "    model_path_this = os.path.join(model_dir, model_name)\n",
    "    \n",
    "    model_time = tnet.ResNet(dim = 3, out_dim =1)\n",
    "    \n",
    "    #inputs outputs for 1 input\n",
    "#     print(train_data.shape)\n",
    "#     train_x = train_data[0,:-1,0]\n",
    "#     print(train_x.shape)\n",
    "#     train_y = train_data[0,1:,0]\n",
    "#     print(train_y.shape)\n",
    "\n",
    "    #inputs and outputs for 2 inputs\n",
    "#     inputs = np.zeros((498, 3))\n",
    "    print(\"train_data shape = \", train_data.shape)\n",
    "    train_data = train_data[:,::step_size]\n",
    "    print(\"train_data shape = \", train_data.shape)\n",
    "    inputs = torch.cat((train_data[:,:-3,0], train_data[:,1:-2,0], train_data[:,2:-1,0]), axis = 2)\n",
    "    print(inputs.shape)\n",
    "    inputs = torch.flatten(inputs, end_dim=1)\n",
    "    #enfore step_size\n",
    "    \n",
    "    print(inputs.shape)\n",
    "    outputs = train_data[:,3:,0]\n",
    "    outputs = torch.flatten(outputs, end_dim=1)\n",
    "#     outputs = outputs[::step_size]\n",
    "    print(outputs.shape)\n",
    "    \n",
    "    #get val data\n",
    "    val_data = val_data[:,::step_size]\n",
    "    val_inputs = torch.cat((val_data[:,:-3,0], val_data[:,1:-2,0], val_data[:,2:-1,0]), axis = 2)\n",
    "    val_inputs = torch.flatten(val_inputs, end_dim=1)\n",
    "    val_outputs = val_data[:,3:,0]\n",
    "    val_outputs = torch.flatten(val_outputs, end_dim=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model_time.parameters())\n",
    "\n",
    "    model_time.train_model(optimizer, criterion,  inputs, outputs, val_inputs, val_outputs)\n",
    "    \n",
    "    return model_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside train_one_timestep\n",
      "train_data shape =  torch.Size([100, 500, 1, 1])\n",
      "train_data shape =  torch.Size([100, 125, 1, 1])\n",
      "torch.Size([100, 122, 3])\n",
      "torch.Size([12200, 3])\n",
      "torch.Size([12200, 1])\n",
      "inputs size =  torch.Size([12200, 3])\n",
      "outputs size =  torch.Size([12200, 1])\n",
      "epoch  0 : train_error:  0.25450617 : val_loss  0.24633789\n",
      "epoch  100 : train_error:  0.045276478 : val_loss  0.0442803\n",
      "epoch  200 : train_error:  0.00085116574 : val_loss  0.0008295963\n",
      "epoch  300 : train_error:  0.00016868535 : val_loss  0.00016721981\n",
      "epoch  400 : train_error:  5.3478383e-05 : val_loss  5.2807583e-05\n",
      "epoch  500 : train_error:  2.4109992e-05 : val_loss  2.3841123e-05\n",
      "epoch  600 : train_error:  1.4386951e-05 : val_loss  1.4424288e-05\n",
      "epoch  700 : train_error:  9.928872e-06 : val_loss  1.0213063e-05\n",
      "epoch  800 : train_error:  7.489805e-06 : val_loss  7.7824325e-06\n",
      "epoch  900 : train_error:  6.0067123e-06 : val_loss  6.2651616e-06\n"
     ]
    }
   ],
   "source": [
    "step_size = 4\n",
    "model_time = train_one_timestep(step_size, train_dict['1'], val_dict['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-6049e6e044bc>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs_first = torch.tensor(inputs[:-1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22cbdb8c6d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(torch.tensor(x[0:1]).unsqueeze(1))\n",
    "# inputs = np.zeros((498, 2))\n",
    "# inputs = torch.cat((train_dict['1'][0,:-2,0], train_dict['1'][0,1:-1,0]), axis = 1)\n",
    "data_smaller = train_dict['1'][:,::step_size]\n",
    "i = 5\n",
    "inputs = torch.cat((data_smaller[i,:-3,0], data_smaller[i,1:-2,0], data_smaller[i,2:-1,0]), axis = 1)\n",
    "outputs = data_smaller[i,3:,0]\n",
    "# inputs = inputs[::step_size]\n",
    "# outputs = outputs[::4]\n",
    "    \n",
    "# inputs = train_dict['1'][0,:-1,0]\n",
    "# outputs = train_dict['1'][0,2:,0]\n",
    "inputs_first = torch.tensor(inputs[:-1])\n",
    "plt.plot(inputs[:,0], label = \"inputs\")\n",
    "# plt.plot(outputs[:,0], label = \"outputs\")#,'--bo')\n",
    "t = 0\n",
    "y_pred = model_time(inputs_first[0:3].float())\n",
    "y_pred = torch.cat((inputs_first[0:3,0:2].float(),y_pred), axis = 1)\n",
    "to_plot = [y_pred.detach().numpy()[0,0]]\n",
    "# plt.plot(t,y_pred.detach().numpy()[0,0],'.')\n",
    "for i in range(int(498/step_size)):\n",
    "    y_next = model_time(y_pred)\n",
    "    y_next = torch.cat((y_pred[:, 1:3],y_next), axis = 1)\n",
    "    to_plot.append(y_next.detach().numpy()[0,0])\n",
    "#     plt.plot(i + 2, y_next.detach().numpy()[0,0],'.')\n",
    "    y_pred = y_next\n",
    "plt.plot(to_plot, label = \"predicted\")\n",
    "plt.legend()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.zeros((498, 2))\n",
    "inputs = torch.cat((train_dict['1'][0,:-2,0], train_dict['1'][0,1:-1,0]), axis = 1)\n",
    "outputs = train_dict['1'][0,2:,0,0]\n",
    "print(outputs.shape)\n",
    "plt.plot(outputs)\n",
    "t = 1\n",
    "y_pred = model_time(inputs[0:2].float())\n",
    "y_pred = torch.cat((inputs[0:2,0:1].float(),y_pred), axis = 1)\n",
    "plt.plot(t,y_pred.detach().numpy()[0,0],'.')\n",
    "for i in range(99):\n",
    "    y_next = model_time(y_pred)\n",
    "    y_next = torch.cat((y_pred[:, 1:2], y_next), axis = 1)\n",
    "    plt.plot(i + 2, y_next.detach().numpy()[0,0],'.')\n",
    "    y_pred = y_next\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#====================================================================================\n",
    "\n",
    "def find_best_timestep(train_data, val_data, test_data, current_size, start_k = 0, largest_k = 7, \n",
    "                       dt = 1, n_forward = 5, noise=0, make_new = False, dont_train = True,\n",
    "                       lr = 1e-3, max_epochs = 10000, batch_size = 50,threshold = 1e-4, \n",
    "                       criterion = torch.nn.MSELoss(reduction='none'), model_dir = \"./models/toy2\",\n",
    "                       i=None, j = None,print_every= 1000):\n",
    "    \"\"\"\n",
    "    Trains models with different timestep sizes and finds lowest error\n",
    "    \n",
    "    inputs:\n",
    "     n_forward = 5, noise=0, make_new = False, dont_train = False):\n",
    "    \n",
    "        train_data: tensor size (n_points, n_timesteps, dim, dim), or  size (n_points, n_timesteps)\n",
    "        val_data:tensor size (n_val_points, n_timesteps, dim, dim) , or  size (n_val_points, n_timesteps)\n",
    "        test_data:tensor size (n_test_points, n_timesteps, dim, dim) , or  size (n_test_points, n_timesteps)\n",
    "        current_size: int, only used in file naming\n",
    "        start_k = 0: int, smallest timestep will be 2**start_k\n",
    "        largest_k = 7:int, largest timestep will be 2**largest_k\n",
    "        dt = 1: float\n",
    "        n_forward = 5: int, number of steps to consider during training\n",
    "        noise=0: float, level of noise, (right now just used in file naming)\n",
    "        make_new = False: boolean, whether or not to make a new model if old already exists\n",
    "        dont_train = False: boolean, whether or not to train more if model loaded\n",
    "        lr = 1e-3: float, learning rate\n",
    "        max_epochs = 10000: int \n",
    "        batch_size = 50: int\n",
    "        threshold=1e-4: float\n",
    "        criterion = torch.nn.MSELoss(reduction='none'))\n",
    "         \n",
    "         \n",
    "    outputs:\n",
    "        models: list of ResNet models\n",
    "        step_sizes: list of ints for the steps_sizes of models \n",
    "        mse_list: list of floats, mse of models \n",
    "        idx_lowest: int, index value with lowest mse\n",
    "         \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #transform data shapes if needed\n",
    "    if(len(train_data.shape)== 2):\n",
    "        train_data = train_data.unsqueeze(2).unsqueeze(3)\n",
    "        val_data = val_data.unsqueeze(2).unsqueeze(3)\n",
    "        test_data = test_data.unsqueeze(2).unsqueeze(3)\n",
    "    assert(len(train_data.shape)== 4)\n",
    "    assert(len(val_data.shape)== 4)\n",
    "    assert(len(test_data.shape)== 4)\n",
    "    \n",
    "    models = list()\n",
    "    step_sizes = list()\n",
    "    n_forward_list = list()\n",
    "    mse_lowest = 1e10 #big number\n",
    "    mse_list = list()\n",
    "    mse_less = 0\n",
    "    idx_lowest = -1\n",
    "    \n",
    "    #make data flat to right dim (n_points, n_timesteps, dim**2)\n",
    "    train_data = torch.flatten(train_data, 2,3)\n",
    "    val_data = torch.flatten(val_data, 2,3)\n",
    "    test_data = torch.flatten(test_data, 2,3)\n",
    "    \n",
    "    n_points, n_timesteps, total_dim = train_data.shape\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for idx, k in enumerate(range(start_k, largest_k)):\n",
    "        step_size = 2**k\n",
    "        step_sizes.append(step_size)\n",
    "        \n",
    "        #going to make n_forward the max if can be \n",
    "#         n_forward = int((np.floor(n_timesteps/step_size)-1)/2)\n",
    "#         n_forward_list.append(n_forward)\n",
    "#         print(\"n_forward = \", n_forward)\n",
    "        \n",
    "        model_time = train_one_timestep(step_size, train_data, val_data, test_data, current_size, \n",
    "                                        make_new = make_new, dont_train = dont_train,i=i, j=j, \n",
    "                                        n_forward=n_forward, max_epochs=max_epochs,model_dir=model_dir, print_every = print_every)\n",
    "        \n",
    "        models.append(model_time)\n",
    "    \n",
    "        #find error\n",
    "        \n",
    "        y_preds = model_time.uni_scale_forecast(val_data[:, 0, :].float(), n_steps=n_timesteps-1)\n",
    "        mse_all = criterion(val_data[:, 1:, :].float(), y_preds).mean(-1)\n",
    "\n",
    "        mean = mse_all.mean(0).detach().numpy()\n",
    "#         print(mean.shape)\n",
    "        mse_less = mean.mean()\n",
    "        mse_list.append(mse_less)\n",
    "\n",
    "        print(\"mse_lowest = \", mse_lowest)\n",
    "        print(\"mse_less= \", mse_less)\n",
    "        \n",
    "        if (mse_less< mse_lowest) or (math.isnan(mse_lowest)) or (math.isnan(mse_less)):\n",
    "            mse_lowest = mse_less\n",
    "            idx_lowest = idx\n",
    "\n",
    "    return models, step_sizes, mse_list, idx_lowest, n_forward_list\n",
    "#====================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_size = 1\n",
    "print(train_dict[str(current_size)].shape)\n",
    "models, step_sizes, mse_list, idx_lowest,n_forward_list = find_best_timestep(train_dict[str(current_size)], \n",
    "                                                              val_dict[str(current_size)], \n",
    "                                                              val_dict[str(current_size)], current_size,model_dir=model_dir,# make_new=True, print_every=100, \n",
    "                                                             start_k=2, largest_k = 3)#, dont_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1500/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot a bunch\n",
    "# # \n",
    "# step_size = 4\n",
    "# dt =1\n",
    "# n_forward = int(500/step_size - 1)\n",
    "# model_name = 'model_L{}_D{}_noise{}.pt'.format(current_size,step_size, 0)\n",
    "# model_path_this = os.path.join(model_dir, model_name)\n",
    "\n",
    "# n_points, n_timesteps, total_dim = torch.flatten(train_dict[str(current_size)], 2,3).shape\n",
    "# arch = [total_dim, 128, 128, 128, total_dim] \n",
    "\n",
    "\n",
    "# model_time = tnet.ResNet(arch=arch, dt=dt, step_size=step_size)\n",
    "\n",
    "# dataset = tnet.DataSet(torch.flatten(train_dict[str(current_size)], 2,3), torch.flatten(val_dict[str(current_size)], 2,3), \n",
    "#                        torch.flatten(val_dict[str(current_size)], 2,3), dt, step_size, n_forward)\n",
    "\n",
    "# #plot the inputed data\n",
    "# plt.figure()\n",
    "# plt.plot(dataset.val_ys[0, :, 0])#, '.')\n",
    "# #     plt.plot(np.arange(len(dataset.val_ys[point_num, :, i]))*dataset.step_size, dataset.val_ys[point_num, :, i], '.')\n",
    "# #     plt.plot(torch.flatten(val_data, 2,3)[0,s_size:,0])\n",
    "# plt.title('step size = '+str(step_size)+\" start\")\n",
    "# #   plt.xlim([0,100])\n",
    "# plt.show()\n",
    "\n",
    "# # training\n",
    "# for i in range(10):\n",
    "#     model_time.train_net(dataset, batch_size = 32, max_epoch=10,model_path=model_path_this)\n",
    "#     models = list()\n",
    "#     models.append(model_time)\n",
    "#     plt.figure()\n",
    "# #     plt.plot(dataset.val_ys[0, :, 0])\n",
    "#     predicted = tnet.multi_scale_forecast(dataset.val_ys[:,0,:],n_forward, models)\n",
    "#     plt.plot(dataset.val_ys[0,:,0], '.')\n",
    "#     plt.plot(predicted[0,:,0])\n",
    "#     plt.title('i = '+str(i))\n",
    "#     #   plt.xlim([0,100])\n",
    "#     plt.show()\n",
    "\n",
    "# # return model_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================\n",
    "def plot_lowest_error(data, model, i = 0):\n",
    "    \"\"\"\n",
    "    Plot data at model, idx\n",
    "    \n",
    "    inputs:\n",
    "        data: tensor of shape (n_points, n_timesteps, dim, dim)\n",
    "        model: Resnet model to predict on \n",
    "        i: int, which validation point to graph\n",
    "    outputs:\n",
    "        No returned values, but graph shown\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    data  = torch.flatten(data, 2,3)\n",
    "    _, total_steps, _ = data.shape\n",
    "    y_preds = model.uni_scale_forecast(torch.tensor(data[:,0,:]).float(), n_steps=total_steps-1)\n",
    "    plt.plot(y_preds[i,:,0], label = \"Predicted\")\n",
    "    plt.plot(data[i,1:,0], label = \"Truth\")\n",
    "    plt.ylim([-.1, 1.1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#====================================================================================\n",
    "\n",
    "print(step_sizes[idx_lowest])    \n",
    "print(step_sizes, mse_list)\n",
    "plot_lowest_error(val_dict[str(current_size)], models[idx_lowest], i =2)\n",
    "\n",
    "# print(train_data.shape)\n",
    "# dataset = tnet.DataSet(torch.flatten(train_data, 2,3), torch.flatten(val_data, 2,3), \n",
    "#                        torch.flatten(val_data, 2,3), 1, step_sizes[idx_lowest], 5)\n",
    "# dataset.plot_val_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_val_data(dataset, point_num = 0, i = 0, other_plot = None):\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(dataset.val_ys[point_num, :, i]))*dataset.step_size, dataset.val_ys[point_num, :, i])#, '.')\n",
    "        if other_plot is not None:\n",
    "            plt.plot(other_plot)\n",
    "#             plt.xlim([0,100])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.train_x.shape)\n",
    "# print(128**2)\n",
    "train_data = train_dict['1']\n",
    "val_data = val_dict['1']\n",
    "plt.plot(val_data[0,:,0,0])\n",
    "print(train_data.shape)\n",
    "s_size = 8\n",
    "dataset = tnet.DataSet(torch.flatten(train_data, 2,3), torch.flatten(val_data, 2,3), \n",
    "                       torch.flatten(val_data, 2,3), 1, s_size, int(np.floor(499/s_size)))\n",
    "# plot_val_data(dataset, other_plot=torch.flatten(val_data, 2,3)[0,s_size:,0])\n",
    "point_num = 0\n",
    "i = 0\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(dataset.val_ys[point_num, :, i]))*dataset.step_size, dataset.val_ys[point_num, :, i])#, '.')\n",
    "plt.plot(np.arange(len(dataset.val_ys[point_num, :, i]))*dataset.step_size, dataset.val_ys[point_num, :, i], '.')\n",
    "plt.plot(torch.flatten(val_data, 2,3)[0,s_size:,0])\n",
    "#   plt.xlim([0,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 32\n",
    "n_forward = int(500/step_size - 1)\n",
    "current_size = 1\n",
    "train_data = train_dict[str(current_size)]\n",
    "val_data = val_dict[str(current_size)]\n",
    "model_time = train_one_timestep(step_size, torch.flatten(train_data, 2,3), \n",
    "                                         torch.flatten(val_data, 2,3),  torch.flatten(val_data, 2,3), \n",
    "                                         1, n_forward=n_forward,  max_epochs = 1000,)\n",
    "dataset = tnet.DataSet(torch.flatten(train_data, 2,3), torch.flatten(val_data, 2,3), \n",
    "                       torch.flatten(val_data, 2,3), 1, step_size, n_forward)\n",
    "# print(model_time(dataset.val_ys[:,0,:],n_forward).shape)\n",
    "models = list()\n",
    "models.append(model_time)\n",
    "predicted = tnet.multi_scale_forecast(dataset.val_ys[:,0,:],n_forward, models)\n",
    "plt.plot(dataset.val_ys[0,:,0], '.')\n",
    "plt.plot(predicted[0,:,0])\n",
    "# plt.xlim([0,500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================\n",
    "def find_error_4(data, model, truth_data, tol = 1e-5):\n",
    "    \"\"\"\n",
    "    Find error over the 4 squares \n",
    "    \n",
    "    inputs:\n",
    "        data: tensor of size (n_points, n_timesteps, dim, dim) to be predicted or size (n_points, n_timesteps)\n",
    "        model: Resnet object to predict data on\n",
    "        truth_data: tensor of size (n_points, n_timesteps, dim_larger, dim_larger) compared on \n",
    "        tol = 1e-5: tolerance level to mark points as resolved or not\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "        \n",
    "    outputs:\n",
    "        resolved: boolean whether complete area is resolved or not\n",
    "        loss: array of floats for size (dim, dim) with mse of each square\n",
    "        unresolved: array of booleans, whether that part is resolved or not. (1 unresolved, 0 resolved)\n",
    "    \"\"\"\n",
    "    if(len(data.shape))==2:\n",
    "        data = data.unsqueeze(2).unsqueeze(3)\n",
    "    assert len(data.shape) == 4\n",
    "    n_points, n_timesteps, dim, _ = data.shape\n",
    "    data  = torch.flatten(data, 2,3)\n",
    "    y_preds = model.uni_scale_forecast(torch.tensor(data[:,0,:]).float(), n_steps=n_timesteps-1).reshape(( n_points, n_timesteps-1, dim,dim))\n",
    "    \n",
    "    _,_, truth_dim, _ = truth_data.shape\n",
    "    assert truth_dim >= dim\n",
    "    \n",
    "    loss = mse(y_preds, truth_data[:,1:])\n",
    "    \n",
    "    resolved =  loss.max() <= tol\n",
    "    unresolved_array = torch.tensor(loss <= tol)\n",
    "    \n",
    "    return resolved, loss, 1-unresolved_array.float()\n",
    "\n",
    "\n",
    "\n",
    "#====================================================================================    \n",
    "    \n",
    "def mse(data1, data2):\n",
    "    \"\"\"\n",
    "    Finds Mean Squared Error between data1 and data2\n",
    "    \n",
    "    inputs:\n",
    "        data1: tensor of shape (n_points, n_timestep, dim1, dim1)\n",
    "        data2: tensor of shape (n_points, n_timestep, dim2, dim2)\n",
    "        \n",
    "    output:\n",
    "        mse: array of size (min_dim, min_dim) with mse \n",
    "    \n",
    "    \"\"\"\n",
    "    #find bigger dim\n",
    "    size1 = data1.shape[-1]\n",
    "    size2 = data2.shape[-1]\n",
    "    size_max = max(size1, size2)\n",
    "    \n",
    "    #grow to save sizes and find mse\n",
    "    mse = np.mean((grow(data1, size_max) - grow(data2, size_max))**2, axis = (0, 1))\n",
    "    return mse\n",
    "#====================================================================================\n",
    "    \n",
    "def grow(data, dim_full=128):\n",
    "    '''\n",
    "    Grow tensor from any size to a bigger size\n",
    "    inputs: \n",
    "        data: tensor to grow, size (n_points, n_timesteps, dim_small, dim_small)\n",
    "        dim_full = 128: int of size to grow data to\n",
    "\n",
    "    outputs:\n",
    "        data_full: tensor size (n_points, n_timesteps, size_full, size_full)\n",
    "    '''\n",
    "    n_points, n_timesteps, dim_small, _ = data.shape \n",
    "    assert dim_full % dim_small == 0 #need small to be multiple of full\n",
    "\n",
    "    divide = dim_full // dim_small\n",
    "\n",
    "    data_full = np.zeros((n_points, n_timesteps, dim_full,dim_full))\n",
    "    for i in range(dim_small):\n",
    "        for j in range(dim_small):\n",
    "            repeated = np.repeat(np.repeat(data[:,:,i,j].reshape(n_points,n_timesteps,1,1), divide, axis = 2), divide, axis = 3)\n",
    "            data_full[:,:,i*divide:(i+1)*divide, j*divide:(j+1)*divide] = repeated\n",
    "    return data_full\n",
    "#====================================================================================\n",
    "\n",
    "\n",
    "resolved, loss, unresolved_list = find_error_4(val_dict['1'], models[idx_lowest], val_dict['2'])\n",
    "print(loss.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unresolved_dict[str(current_size)] = torch.tensor(unresolved_list)\n",
    "\n",
    "print(unresolved_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_train_data = unresolved_list * train_dict[str(current_size*2)]\n",
    "print(next_train_data.shape)\n",
    "plt.imshow(next_train_data[0,0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keep.append(models[idx_lowest])\n",
    "model_used_dict[str(current_size)] = [[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================\n",
    "def find_error_1(data, model, tol = 1e-5):\n",
    "    \"\"\"\n",
    "    Find error over the 1 square\n",
    "    \n",
    "    inputs:\n",
    "        data: tensor of size (n_points, n_timesteps, dim, dim) to be predicted\n",
    "        model: Resnet object to predict data on\n",
    "        tol = 1e-5: tolerance level to mark points as resolved or not\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "        \n",
    "    outputs:\n",
    "        loss: float of mse\n",
    "        resolved: boolean whether resolved or not\n",
    "    \"\"\"\n",
    "    n_points, n_timesteps  = data.shape\n",
    "    dim = 1\n",
    "    data_input  = data.unsqueeze(2)\n",
    "    y_preds = model.uni_scale_forecast(torch.tensor(data_input[:,0,:]).float(), n_steps=n_timesteps-1).reshape(( n_points, n_timesteps-1, dim,dim))\n",
    "    data1 = data[:,1:]\n",
    "    data2 = y_preds[:,:,0,0]\n",
    "#     print()\n",
    "    loss = torch.mean((data1-data2)**2)#mse(y_preds, data[:,1:])\n",
    "    \n",
    "#     print(loss)\n",
    "    \n",
    "    return loss, loss <= tol\n",
    "\n",
    "#====================================================================================\n",
    "\n",
    "\n",
    "current_size = 2\n",
    "next_train_data = unresolved_list * train_dict[str(current_size)]\n",
    "\n",
    "model_idx_list = np.ones((current_size, current_size))*(-1) #start with all -1\n",
    "\n",
    "for i in range(current_size):\n",
    "    for j in range(current_size):\n",
    "        data_this = next_train_data[:,:,i,j]\n",
    "        if (torch.min(data_this) == 0) and (torch.max(data_this) == 0):\n",
    "            #don't need to do anything is model is resolved\n",
    "            continue\n",
    "        else:\n",
    "        #see if the error is low enough on already made model\n",
    "            for m, model in enumerate(model_keep):\n",
    "                loss, resolved = find_error_1(data_this, model)\n",
    "                step_size = model.step_size\n",
    "                print(\"loss = \", loss)\n",
    "                print(\"step_size = \", step_size)\n",
    "                if resolved:\n",
    "                    model_idx_list[i,j] == m\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "            if not resolved:\n",
    "                i = 0\n",
    "                j = 1\n",
    "                k = int(np.log2(step_size))\n",
    "                print(\"k = \", k)\n",
    "                print(\"train_dict[str(current_size)][:,:,i,j] shape = \", train_dict[str(current_size)][:,:,i,j].shape)\n",
    "                #if no model good, train new model\n",
    "                models, step_sizes, mse_list, idx_lowest = find_best_timestep(train_dict[str(current_size)][:,:,i,j], \n",
    "                                                              val_dict[str(current_size)][:,:,i,j], \n",
    "                                                              val_dict[str(current_size)][:,:,i,j], current_size,model_dir=model_dir,\n",
    "                                                              i=i, j=j, start_k = max(0,k-1), largest_k = k+2)\n",
    "                \n",
    "                vbnm\n",
    "                resolved, loss, unresolved_list = find_error_4(val_dict[str(current_size)][:,:,i,j], \n",
    "                                                               models[idx_lowest], \n",
    "                                                               val_dict[str(current_size)][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size])\n",
    "                model_keep.append(models[idx_lowest])\n",
    "                model_idx_list[i,j] == len(model_keep) #last model will be the one for this square\n",
    "            \n",
    "#             predicted = model.uni_scale_forecast(torch.tensor(data[:,0,:]).float(), n_steps=n_timesteps-1).reshape((  n_points, n_timesteps-1, dim,dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(step_sizes, mse_list, idx_lowest)\n",
    "resolved, loss, unresolved_list = find_error_4(val_dict[str(current_size)][:,:,i,j], \n",
    "                                                               models[idx_lowest], \n",
    "                                                               val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size])\n",
    "print(loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  models[idx_lowest]\n",
    "print(idx_lowest)\n",
    "n_timesteps = 500\n",
    "n_points = 10\n",
    "dim = 1\n",
    "# plt.plot(model(val_dict[str(current_size)][:,:,i,j].unsqueeze(2).unsqueeze(3))[0,:,0,0].detach().numpy(), label = \"predicted\")\n",
    "print(val_dict[str(current_size)][:,0,i,j].unsqueeze(1).shape)\n",
    "val_data_this = val_dict[str(current_size)][:,0,i,j].unsqueeze(1)\n",
    "predicted = model.uni_scale_forecast(val_data_this, n_steps=n_timesteps-1)\n",
    "print(predicted.shape)\n",
    "predicted_reshape = predicted.reshape((  n_points, n_timesteps-1, dim,dim))\n",
    "plt.plot(predicted_reshape[0,:,0], label = \"predicted\")\n",
    "print(val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size].shape)\n",
    "# plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,0], label = \"Truth\")\n",
    "\n",
    "plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,1], label = \"Truth\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_dict[str(current_size*2)][0,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = (16+32)/2\n",
    "print(step_size)\n",
    "model = train_one_timestep(int(28), train_dict[str(current_size)][:,:,i,j].unsqueeze(2), \n",
    "                           val_dict[str(current_size)][:,:,i,j].unsqueeze(2), \n",
    "                           val_dict[str(current_size)][:,:,i,j].unsqueeze(2), current_size)\n",
    "#                        dt = 1, n_forward = 5, noise=0, make_new = False, dont_train = True, \n",
    "#                        lr = 1e-3, max_epochs = 10000, batch_size = 50,threshold = 1e-4, \n",
    "#                        model_dir = './models/toy2',i=None, j = None):\n",
    "    \n",
    "#     train_dict[str(current_size)][:,:,i,j], \n",
    "#                                                               val_dict[str(current_size)][:,:,i,j], \n",
    "#                                                               val_dict[str(current_size)][:,:,i,j], current_size,model_dir=model_dir, \n",
    "#                                                               i=i, j=j, start_k = max(0,k-1), largest_k = k+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "resolved, loss, unresolved_list = find_error_4(val_dict[str(current_size)][:,:,i,j], \n",
    "                                                               model, \n",
    "                                                               val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  models[idx_lowest]\n",
    "print(idx_lowest)\n",
    "n_timesteps = 500\n",
    "n_points = 10\n",
    "dim = 1\n",
    "# plt.plot(model(val_dict[str(current_size)][:,:,i,j].unsqueeze(2).unsqueeze(3))[0,:,0,0].detach().numpy(), label = \"predicted\")\n",
    "print(val_dict[str(current_size)][:,0,i,j].unsqueeze(1).shape)\n",
    "val_data_this = val_dict[str(current_size)][:,0,i,j].unsqueeze(1)\n",
    "predicted = model.uni_scale_forecast(val_data_this, n_steps=n_timesteps-1)\n",
    "print(predicted.shape)\n",
    "predicted_reshape = predicted.reshape((  n_points, n_timesteps-1, dim,dim))\n",
    "plt.plot(predicted_reshape[0,:,0], label = \"predicted\")\n",
    "print(val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size].shape)\n",
    "# plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,0], label = \"Truth\")\n",
    "\n",
    "plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,1], label = \"Truth\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
