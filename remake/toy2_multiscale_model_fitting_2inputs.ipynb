{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiscale model fitting for Toy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start with initalizing many things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "# import sys\n",
    "import torch\n",
    "# import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm.notebook import tqdm\n",
    "# import time\n",
    "import math\n",
    "\n",
    "# module_path = os.path.abspath(os.path.join('../src/'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "    \n",
    "    \n",
    "# import torch_cae_multilevel_V4 as net\n",
    "import ResNet2 as tnet\n",
    "# import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "data_dir = './data/toy2'\n",
    "model_dir = './model/toy2'\n",
    "result_dir = './result/toy2'\n",
    "\n",
    "#load data\n",
    "train_data = torch.tensor(np.load(os.path.join(data_dir, 'train_data.npy')))\n",
    "val_data = torch.tensor(np.load(os.path.join(data_dir, 'val_data.npy')))\n",
    "test_data = torch.tensor(np.load(os.path.join(data_dir, 'test_data.npy')))\n",
    "\n",
    "data_of_sizes = {}\n",
    "current_size = 2\n",
    "unresolved_dict = {}\n",
    "model_keep = list()\n",
    "model_used_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions, will move these to a utils file eventually \n",
    "#====================================================================================\n",
    "# def data_of_size(data,size):\n",
    "#     \"\"\"\n",
    "#     Takes averages to shrink size of data\n",
    "#     Takes data of size (n_points, dim, dim) and shrinks to size (n_points, size, size)\n",
    "#     takes averages to shrink\n",
    "#     \"\"\"\n",
    "#     return decrease_to_size(torch.tensor(data).unsqueeze(1), size)[:,0,:,:]\n",
    "#====================================================================================\n",
    "\n",
    "\n",
    "def isPowerOfTwo(n):\n",
    "    \"\"\"\n",
    "    checks if n is a power of two\n",
    "    \n",
    "    input: n, int\n",
    "    \n",
    "    output: boolean\n",
    "    \"\"\"\n",
    "    return (np.ceil(np.log2(n)) == np.floor(np.log2(n)));\n",
    "#====================================================================================\n",
    "def shrink(data, low_dim):\n",
    "    '''\n",
    "    Shrinks data to certain size; either averages or takes endpoints\n",
    "    \n",
    "    inputs:\n",
    "        data: array of size (n_points, n_timesteps, dim, dim) that will shrink\n",
    "        low_dim: int, size to shrink to, low_dim must be less than or equal to dim\n",
    "        \n",
    "    output:\n",
    "        data: array of size (n_points, n_timesteps, low_dim, low_dim)\n",
    "    '''\n",
    "    \n",
    "    #check inputs\n",
    "    assert len(data.shape) == 4\n",
    "    n_points, n_timesteps, dim, _ = data.shape\n",
    "    assert dim >= low_dim\n",
    "    assert isPowerOfTwo(low_dim)\n",
    "    \n",
    "    if dim == low_dim: #same size, no change\n",
    "        return data\n",
    "    \n",
    "    while(dim > low_dim):\n",
    "        #shrink by 1 level until same size\n",
    "        data = apply_local_op(data.float(), 'cpu', ave=average)\n",
    "        current_size = data.shape[-1]\n",
    "        \n",
    "    return data\n",
    "#====================================================================================\n",
    "def ave_one_level(data):\n",
    "    '''\n",
    "    takes averages to shrink data 1 level\n",
    "    \n",
    "    inputs:\n",
    "        data: tensor of size (n_points, n_timesteps, dim, dim) that will shrink\n",
    "        \n",
    "    output:\n",
    "        processed data: tensor of size (n_points, n_timesteps, dim/2, dim/2)\n",
    "    '''\n",
    "    device = 'cpu'\n",
    "    if not torch.is_tensor(data): #needs to be a tensor\n",
    "        data = torch.tensor(data)\n",
    "        \n",
    "    assert len(data.shape) == 4\n",
    "#     if data.shape != 4:\n",
    "#         print(\"data.shape = \", data.shape)\n",
    "#         print(\"data.shape should be of length 4\")\n",
    "    n_points, n_timesteps, dim, _ = data.shape\n",
    "    \n",
    "    #dim needs to be even \n",
    "    assert dim % 2 == 0\n",
    "    \n",
    "    data_right_size = torch.flatten(data, 0,1).unsqueeze(1).float()\n",
    "    \n",
    "#     n = min(in_channels, out_channels)\n",
    "    op = torch.nn.Conv2d(1, 1, 2, stride=2, padding=0).to(device)\n",
    "   \n",
    "    op.weight.data = torch.zeros(op.weight.data.size()).to(device)\n",
    "    op.bias.data = torch.zeros(op.bias.data.size()).to(device)\n",
    "    op.weight.data[0,0, :, :] = torch.ones(op.weight.data[0,0, :, :].size()).to(device) / 4\n",
    "\n",
    "    # make them non-trainable\n",
    "    for param in op.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    print(\"Transforming\")\n",
    "        \n",
    "    shrunk = op(data_right_size)\n",
    "    \n",
    "    print(\"reshape to print\")\n",
    "    \n",
    "    return shrunk.squeeze(1).reshape((n_points, n_timesteps, dim//2, dim//2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data.shape)\n",
    "# processed = ave_one_level(train_data)\n",
    "# print(processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make a dictionary with train data of every size 128->1\n",
    "#====================================================================================\n",
    "\n",
    "def make_dict_all_sizes(data):\n",
    "    \"\"\"\n",
    "    Makes a dictionary of data at every refinedment size from current->1\n",
    "    \n",
    "    inputs:\n",
    "        data: tensor(or array) of size (n_points, n_timesteps, dim, dim)\n",
    "        \n",
    "    outputs: \n",
    "        dic: dictionary of tensors. Keys are dim size, tensors are size (n_points, n_timesteps, dim, dim)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_points, n_timesteps, dim, _ = data.shape\n",
    "    \n",
    "    if not torch.is_tensor(data): #needs to be a tensor\n",
    "        data = torch.tensor(data)\n",
    "        \n",
    "    assert isPowerOfTwo(dim)\n",
    "        \n",
    "    dic = {str(dim): data}\n",
    "    \n",
    "    for i in range(int(np.log2(dim))):\n",
    "        #decrease\n",
    "        print(\"i = \", i)\n",
    "        data = ave_one_level(data)\n",
    "        dic[str(data.shape[-1])] = data\n",
    "    \n",
    "    print(dic.keys())\n",
    "    \n",
    "    return dic\n",
    "#====================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  1\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  2\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  3\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  4\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  5\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  6\n",
      "Transforming\n",
      "reshape to print\n",
      "dict_keys(['128', '64', '32', '16', '8', '4', '2', '1'])\n",
      "i =  0\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  1\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  2\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  3\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  4\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  5\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  6\n",
      "Transforming\n",
      "reshape to print\n",
      "dict_keys(['128', '64', '32', '16', '8', '4', '2', '1'])\n"
     ]
    }
   ],
   "source": [
    "train_dict = make_dict_all_sizes(train_data)\n",
    "val_dict = make_dict_all_sizes(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================\n",
    "def train_one_timestep(step_size, train_data, val_data, test_data, current_size, \n",
    "                       dt = 1, n_forward = 5, noise=0, make_new = False, dont_train = True, \n",
    "                       lr = 1e-3, max_epochs = 10000, batch_size = 50,threshold = 1e-4, \n",
    "                       model_dir = './models/toy2',i=None, j = None):\n",
    "\n",
    "    \"\"\"\n",
    "    fits or loads model at 1 timestep\n",
    "    \n",
    "    inputs:\n",
    "        step_size: int \n",
    "        train_data: tensor size (n_points, n_timesteps, dim**2) \n",
    "        val_data:tensor size (n_val_points, n_timesteps, dim**2) \n",
    "        test_data:tensor size (n_test_points, n_timesteps, dim**2) \n",
    "        current_size: int, only used in file naming\n",
    "        dt = 1: float\n",
    "        n_forward = 5: int, number of steps to consider during training\n",
    "        noise=0: float, level of noise, (right now just used in file naming)\n",
    "        make_new = False: boolean, whether or not to make a new model if old already exists\n",
    "        dont_train = True: boolean, whether or not to train more if model loaded\n",
    "        lr = 1e-3: float, learning rate\n",
    "        max_epochs = 10000: int \n",
    "        batch_size = 50: int\n",
    "        threshold=1e-4: float, stop training when validation gets below threshold\n",
    "         \n",
    "    \n",
    "    outputs:\n",
    "        model_time: ResNet object of trained model. Also saved\n",
    "    \"\"\"\n",
    "    if (i is not None) and (j is not None):\n",
    "        \n",
    "        model_name = 'model_L{}_D{}_noise{}_i{}_j{}.pt'.format(current_size,step_size, noise, i, j)\n",
    "    else:\n",
    "        model_name = 'model_L{}_D{}_noise{}.pt'.format(current_size,step_size, noise)\n",
    "    model_path_this = os.path.join(model_dir, model_name)\n",
    "    \n",
    "    n_points, n_timesteps, total_dim = train_data.shape\n",
    "    arch = [total_dim*2, 128, 128, 128, total_dim*2] \n",
    "    \n",
    "    try: #if we already have a model saved\n",
    "        if make_new:\n",
    "            print(\"Making a new model. Old one deleted. model {}\".format(model_name))\n",
    "            assert False\n",
    "        model_time = torch.load(model_path_this)\n",
    "        print(\"model loaded: \", model_name)\n",
    "        print(\"don't train = \", dont_train)\n",
    "        if dont_train: #just load model, no training\n",
    "            return model_time\n",
    "    except:\n",
    "        print('create model {} ...'.format(model_name))\n",
    "#         model_time = tnet.ResNet(arch=arch, dt=dt, step_size=step_size)\n",
    "        model_time = ResNet(arch=arch, dt=dt, step_size=step_size)\n",
    "\n",
    "    dataset = tnet.DataSet(train_data, val_data, test_data, dt, step_size, n_forward)\n",
    "    \n",
    "    \n",
    "    # training\n",
    "    model_time.train_net(dataset, max_epoch=max_epochs, batch_size=batch_size, lr=lr,\n",
    "                    model_path=model_path_this,threshold= threshold)\n",
    "    \n",
    "    return model_time\n",
    "#====================================================================================\n",
    "\n",
    "def find_best_timestep(train_data, val_data, test_data, current_size, start_k = 0, largest_k = 7, \n",
    "                       dt = 1, n_forward = 5, noise=0, make_new = False, dont_train = True,\n",
    "                       lr = 1e-3, max_epochs = 10000, batch_size = 50,threshold = 1e-4, \n",
    "                       criterion = torch.nn.MSELoss(reduction='none'), model_dir = \"./models/toy2\",\n",
    "                       i=None, j = None):\n",
    "    \"\"\"\n",
    "    Trains models with different timestep sizes and finds lowest error\n",
    "    \n",
    "    inputs:\n",
    "     n_forward = 5, noise=0, make_new = False, dont_train = False):\n",
    "    \n",
    "        train_data: tensor size (n_points, n_timesteps, dim, dim), or  size (n_points, n_timesteps)\n",
    "        val_data:tensor size (n_val_points, n_timesteps, dim, dim) , or  size (n_val_points, n_timesteps)\n",
    "        test_data:tensor size (n_test_points, n_timesteps, dim, dim) , or  size (n_test_points, n_timesteps)\n",
    "        current_size: int, only used in file naming\n",
    "        start_k = 0: int, smallest timestep will be 2**start_k\n",
    "        largest_k = 7:int, largest timestep will be 2**largest_k\n",
    "        dt = 1: float\n",
    "        n_forward = 5: int, number of steps to consider during training\n",
    "        noise=0: float, level of noise, (right now just used in file naming)\n",
    "        make_new = False: boolean, whether or not to make a new model if old already exists\n",
    "        dont_train = False: boolean, whether or not to train more if model loaded\n",
    "        lr = 1e-3: float, learning rate\n",
    "        max_epochs = 10000: int \n",
    "        batch_size = 50: int\n",
    "        threshold=1e-4: float\n",
    "        criterion = torch.nn.MSELoss(reduction='none'))\n",
    "         \n",
    "         \n",
    "    outputs:\n",
    "        models: list of ResNet models\n",
    "        step_sizes: list of ints for the steps_sizes of models \n",
    "        mse_list: list of floats, mse of models \n",
    "        idx_lowest: int, index value with lowest mse\n",
    "         \n",
    "    \"\"\"\n",
    "    #transform data shapes if needed\n",
    "    if(len(train_data.shape)== 2):\n",
    "        train_data = train_data.unsqueeze(2).unsqueeze(3)\n",
    "        val_data = val_data.unsqueeze(2).unsqueeze(3)\n",
    "        test_data = test_data.unsqueeze(2).unsqueeze(3)\n",
    "    assert(len(train_data.shape)== 4)\n",
    "    assert(len(val_data.shape)== 4)\n",
    "    assert(len(test_data.shape)== 4)\n",
    "    \n",
    "    models = list()\n",
    "    step_sizes = list()\n",
    "    mse_lowest = 1e10 #big number\n",
    "    mse_list = list()\n",
    "    mse_less = 0\n",
    "    idx_lowest = -1\n",
    "    \n",
    "    #make data flat to right dim (n_points, n_timesteps, dim**2)\n",
    "    train_data = torch.flatten(train_data, 2,3)\n",
    "    val_data = torch.flatten(val_data, 2,3)\n",
    "    test_data = torch.flatten(test_data, 2,3)\n",
    "    \n",
    "    n_points, n_timesteps, total_dim = train_data.shape\n",
    "    \n",
    "    for idx, k in enumerate(range(start_k, largest_k)):\n",
    "        step_size = 2**k\n",
    "        step_sizes.append(step_size)\n",
    "        model_time = train_one_timestep(step_size, train_data, val_data, test_data, current_size, \n",
    "                                        make_new = make_new, dont_train = dont_train,i=i, j=j)\n",
    "        models.append(model_time)\n",
    "    \n",
    "        #find error\n",
    "        \n",
    "        y_preds = model_time.uni_scale_forecast(val_data[:, 0, :].float(), n_steps=n_timesteps-1)\n",
    "        mse_all = criterion(val_data[:, 1:, :].float(), y_preds).mean(-1)\n",
    "\n",
    "        mean = mse_all.mean(0).detach().numpy()\n",
    "#         print(mean.shape)\n",
    "        mse_less = mean.mean()\n",
    "        mse_list.append(mse_less)\n",
    "\n",
    "        print(\"mse_lowest = \", mse_lowest)\n",
    "        print(\"mse_less= \", mse_less)\n",
    "        \n",
    "        if (mse_less< mse_lowest) or (math.isnan(mse_lowest)) or (math.isnan(mse_less)):\n",
    "            mse_lowest = mse_less\n",
    "            idx_lowest = idx\n",
    "\n",
    "    return models, step_sizes, mse_list, idx_lowest\n",
    "#====================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "from utils_time2 import DataSet\n",
    "\n",
    "\n",
    "class NNBlock(torch.nn.Module):\n",
    "    def __init__(self, arch, activation=torch.nn.ReLU()):\n",
    "        \"\"\"\n",
    "        :param arch: architecture of the nn_block\n",
    "        :param activation: activation function\n",
    "        \"\"\"\n",
    "        super(NNBlock, self).__init__()\n",
    "\n",
    "        # param\n",
    "        self.n_layers = len(arch)-1\n",
    "        self.activation = activation\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # network arch\n",
    "        for i in range(self.n_layers):\n",
    "            self.add_module('Linear_{}'.format(i), torch.nn.Linear(arch[i], arch[i+1]).to(self.device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: input of nn\n",
    "        :return: output of nn\n",
    "        \"\"\"\n",
    "        for i in range(self.n_layers - 1):\n",
    "            x = self.activation(self._modules['Linear_{}'.format(i)](x))\n",
    "        # no nonlinear activations in the last layer\n",
    "        x = self._modules['Linear_{}'.format(self.n_layers - 1)](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, arch, dt, step_size, activation=torch.nn.ReLU()):\n",
    "        \"\"\"\n",
    "        :param arch: a list that provides the architecture\n",
    "        :param dt: time step unit\n",
    "        :param step_size: forward step size\n",
    "        :param activation: activation function in neural network\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        # check consistencies\n",
    "        assert isinstance(arch, list)\n",
    "        assert arch[0] == arch[-1]\n",
    "\n",
    "        # param\n",
    "        self.n_dim = arch[0]\n",
    "\n",
    "        # data\n",
    "        self.dt = dt\n",
    "        self.step_size = step_size\n",
    "\n",
    "        # device\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # layer\n",
    "        self.activation = activation\n",
    "        self.add_module('increment', NNBlock(arch, activation=activation))\n",
    "\n",
    "    def check_data_info(self, dataset):\n",
    "        \"\"\"\n",
    "        :param: dataset: a dataset object\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        print(\"self.n_dim= \", self.n_dim)\n",
    "        print(\"dataset.n_dim = \", dataset.n_dim)\n",
    "        assert self.n_dim == dataset.n_dim\n",
    "        assert self.dt == dataset.dt\n",
    "        assert self.step_size == dataset.step_size\n",
    "\n",
    "    def forward(self, x_init):\n",
    "        \"\"\"\n",
    "        :param x_init: array of shape batch_size x input_dim\n",
    "        :return: next step prediction of shape batch_size x input_dim\n",
    "        \"\"\"\n",
    "        return x_init + self._modules['increment'](x_init)\n",
    "\n",
    "    def uni_scale_forecast(self, x_init, n_steps, interpolate = True):\n",
    "        \"\"\"\n",
    "        :param x_init: array of shape n_test x input_dim\n",
    "        :param n_steps: number of steps forward in terms of dt\n",
    "        :return: predictions of shape n_test x n_steps x input_dim and the steps\n",
    "        \"\"\"\n",
    "        steps = list()\n",
    "        preds = list()\n",
    "        sample_steps = range(n_steps)\n",
    "\n",
    "        # forward predictions\n",
    "        x_prev = x_init\n",
    "        cur_step = self.step_size - 1\n",
    "        while cur_step < n_steps + self.step_size:\n",
    "            x_next = self.forward(x_prev)\n",
    "            steps.append(cur_step)\n",
    "            preds.append(x_next)\n",
    "            cur_step += self.step_size\n",
    "            x_prev = x_next\n",
    "\n",
    "        # include the initial frame\n",
    "        steps.insert(0, 0)\n",
    "        preds.insert(0, torch.tensor(x_init).float().to(self.device))\n",
    "\n",
    "        # interpolations\n",
    "        preds = torch.stack(preds, 2).detach().numpy()\n",
    "        cs = scipy.interpolate.interp1d(steps, preds, kind='linear')\n",
    "        y_preds = torch.tensor(cs(sample_steps)).transpose(1, 2).float()\n",
    "\n",
    "        return y_preds\n",
    "\n",
    "    def train_net(self, dataset, max_epoch, batch_size, w=1.0, lr=1e-3, model_path=None, threshold = 1e-8):\n",
    "        \"\"\"\n",
    "        :param dataset: a dataset object\n",
    "        :param max_epoch: maximum number of epochs\n",
    "        :param batch_size: batch size\n",
    "        :param w: l2 error weight\n",
    "        :param lr: learning rate\n",
    "        :param model_path: path to save the model\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # check consistency\n",
    "        self.check_data_info(dataset)\n",
    "\n",
    "        # training\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        epoch = 0\n",
    "        best_loss = 1e+5\n",
    "        while epoch < max_epoch:\n",
    "            epoch += 1\n",
    "            # ================= prepare data ==================\n",
    "            n_samples = dataset.n_train\n",
    "            new_idxs = torch.randperm(n_samples)\n",
    "            batch_x = dataset.train_x[new_idxs[:batch_size], :]\n",
    "            batch_ys = dataset.train_ys[new_idxs[:batch_size], :, :]\n",
    "            # =============== calculate losses ================\n",
    "            train_loss = self.calculate_loss(batch_x, batch_ys, w=w)\n",
    "            val_loss = self.calculate_loss(dataset.val_x, dataset.val_ys, w=w)\n",
    "            # ================ early stopping =================\n",
    "            if best_loss <= threshold:\n",
    "                print('--> model has reached an accuracy of ', threshold, '! Finished training!')\n",
    "                break\n",
    "            # =================== backward ====================\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            # =================== log =========================\n",
    "            if epoch % 1000 == 0:\n",
    "                print('epoch {}, training loss {}, validation loss {}'.format(epoch, train_loss.item(),\n",
    "                                                                              val_loss.item()))\n",
    "                if val_loss.item() < best_loss:\n",
    "                    best_loss = val_loss.item()\n",
    "                    if model_path is not None:\n",
    "                        print('(--> new model saved @ epoch {})'.format(epoch))\n",
    "                        torch.save(self, model_path)\n",
    "\n",
    "        # if to save at the end\n",
    "        if val_loss.item() < best_loss and model_path is not None:\n",
    "            print('--> new model saved @ epoch {}'.format(epoch))\n",
    "            torch.save(self, model_path)\n",
    "\n",
    "    def calculate_loss(self, x, ys, w=1.0):\n",
    "        \"\"\"\n",
    "        :param x: x batch, array of size batch_size x n_dim\n",
    "        :param ys: ys batch, array of size batch_size x n_steps x n_dim\n",
    "        :return: overall loss\n",
    "        \"\"\"\n",
    "        batch_size, n_steps, n_dim = ys.size()\n",
    "#         assert n_dim == self.n_dim\n",
    "\n",
    "        # forward (recurrence)\n",
    "        y_preds = torch.zeros(batch_size, n_steps, n_dim*2).float().to(self.device)\n",
    "        y_prev_0 = x[:,0]\n",
    "        y_prev_1 = x[:,1]\n",
    "        for t in range(n_steps-1):\n",
    "#             print(\"start loop\")\n",
    "#             print(\"t = \", t)\n",
    "#             print(\"y_prev_0  = \", y_prev_0.shape)\n",
    "#             print(\"y_prev_1  = \", y_prev_1.shape)\n",
    "            \n",
    "#             print(\"torch.cat((y_prev_0, y_prev_1), 0).shape= \", torch.cat((y_prev_0, y_prev_1), 1).shape)\n",
    "#             ghj\n",
    "            y_next = self.forward(torch.cat((y_prev_0, y_prev_1), 1))\n",
    "#             print(\"y_next shape = \", y_next.shape)\n",
    "            y_preds[:, t, :] = y_next\n",
    "            y_prev_1 = torch.clone(y_prev_0)\n",
    "#             print(\"y_prev_1  = \", y_prev_1.shape)\n",
    "            y_prev_0 = torch.clone(y_next[:,1]).unsqueeze(1)\n",
    "#             print(\"y_prev_0  = \", y_prev_0.shape)\n",
    "#             print(\"end loop\")\n",
    "\n",
    "        # compute loss\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "        loss = w * criterion(y_preds, ys).mean() + (1-w) * criterion(y_preds, ys).max()\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def multi_scale_forecast(x_init, n_steps, models):\n",
    "    \"\"\"\n",
    "    :param x_init: initial state torch array of shape n_test x n_dim\n",
    "    :param n_steps: number of steps forward in terms of dt\n",
    "    :param models: a list of models\n",
    "    :return: a torch array of size n_test x n_steps x n_dim\n",
    "\n",
    "    This function is not used in the paper for low efficiency,\n",
    "    we suggest to use vectorized_multi_scale_forecast() below.\n",
    "    \"\"\"\n",
    "    # sort models by their step sizes (decreasing order)\n",
    "    step_sizes = [model.step_size for model in models]\n",
    "    models = [model for _, model in sorted(zip(step_sizes, models), reverse=True)]\n",
    "\n",
    "    # parameters\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    n_extended_steps = n_steps + min(step_sizes)\n",
    "    sample_steps = range(1, n_steps+1)\n",
    "\n",
    "    steps = list()\n",
    "    preds = list()\n",
    "    steps.insert(0, 0)\n",
    "    preds.insert(0, torch.tensor(x_init).float().to(device))\n",
    "    for model in models:\n",
    "        tmp_steps = list()\n",
    "        tmp_preds = list()\n",
    "        for j in range(len(steps)):\n",
    "            if j < len(steps) - 1:\n",
    "                end_step = steps[j+1]\n",
    "            else:\n",
    "                end_step = n_extended_steps\n",
    "            # starting point\n",
    "            cur_step = steps[j]\n",
    "            cur_x = preds[j]\n",
    "            tmp_steps.append(cur_step)\n",
    "            tmp_preds.append(cur_x)\n",
    "            while True:\n",
    "                step_size = model.step_size\n",
    "                cur_step += step_size\n",
    "                if cur_step >= end_step:\n",
    "                    break\n",
    "                cur_x = model(cur_x)\n",
    "                tmp_steps.append(cur_step)\n",
    "                tmp_preds.append(cur_x)\n",
    "        # update new predictions\n",
    "        steps = tmp_steps\n",
    "        preds = tmp_preds\n",
    "\n",
    "    # interpolation\n",
    "    preds = torch.stack(preds, 2).detach().numpy()\n",
    "    cs = scipy.interpolate.interp1d(steps, preds, kind='linear')\n",
    "    y_preds = torch.tensor(cs(sample_steps)).transpose(1, 2).float()\n",
    "\n",
    "    return y_preds\n",
    "\n",
    "\n",
    "def vectorized_multi_scale_forecast(x_init, n_steps, models):\n",
    "    \"\"\"\n",
    "    :param x_init: initial state torch array of shape n_test x n_dim\n",
    "    :param n_steps: number of steps forward in terms of dt\n",
    "    :param models: a list of models\n",
    "    :return: a torch array of size n_test x n_steps x n_dim,\n",
    "             a list of indices that are not achieved by interpolations\n",
    "    \"\"\"\n",
    "    # sort models by their step sizes (decreasing order)\n",
    "    step_sizes = [model.step_size for model in models]\n",
    "    models = [model for _, model in sorted(zip(step_sizes, models), reverse=True)]\n",
    "\n",
    "    # we assume models are sorted by their step sizes (decreasing order)\n",
    "    n_test, n_dim = x_init.shape\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    indices = list()\n",
    "    extended_n_steps = n_steps + models[0].step_size\n",
    "    preds = torch.zeros(n_test, extended_n_steps + 1, n_dim).float().to(device)\n",
    "\n",
    "    # vectorized simulation\n",
    "    indices.append(0)\n",
    "    preds[:, 0, :] = x_init\n",
    "    total_step_sizes = n_steps\n",
    "    for model in models:\n",
    "        n_forward = int(total_step_sizes/model.step_size)\n",
    "        y_prev = preds[:, indices, :].reshape(-1, n_dim)\n",
    "        indices_lists = [indices]\n",
    "        for t in range(n_forward):\n",
    "            y_next = model(y_prev)\n",
    "            shifted_indices = [x + (t + 1) * model.step_size for x in indices]\n",
    "            indices_lists.append(shifted_indices)\n",
    "            preds[:, shifted_indices, :] = y_next.reshape(n_test, -1, n_dim)\n",
    "            y_prev = y_next\n",
    "        indices = [val for tup in zip(*indices_lists) for val in tup]\n",
    "        total_step_sizes = model.step_size - 1\n",
    "\n",
    "    # simulate the tails\n",
    "    last_idx = indices[-1]\n",
    "    y_prev = preds[:, last_idx, :]\n",
    "    while last_idx < n_steps:\n",
    "        last_idx += models[-1].step_size\n",
    "        y_next = models[-1](y_prev)\n",
    "        preds[:, last_idx, :] = y_next\n",
    "        indices.append(last_idx)\n",
    "        y_prev = y_next\n",
    "\n",
    "    # interpolations\n",
    "    sample_steps = range(1, n_steps+1)\n",
    "    valid_preds = preds[:, indices, :].detach().numpy()\n",
    "    cs = scipy.interpolate.interp1d(indices, valid_preds, kind='linear', axis=1)\n",
    "    y_preds = torch.tensor(cs(sample_steps)).float()\n",
    "\n",
    "    return y_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a new model. Old one deleted. model model_L1_D32_noise0.pt\n",
      "create model model_L1_D32_noise0.pt ...\n",
      "self.n_dim=  2\n",
      "dataset.n_dim =  2\n",
      "epoch 1000, training loss 0.07499005645513535, validation loss 0.11027058959007263\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.06968417763710022, validation loss 0.10850071907043457\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.06272616982460022, validation loss 0.10779464989900589\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.06694997102022171, validation loss 0.10830338299274445\n",
      "epoch 5000, training loss 0.06016601622104645, validation loss 0.10659757256507874\n",
      "(--> new model saved @ epoch 5000)\n",
      "epoch 6000, training loss 0.08017755299806595, validation loss 0.10648494958877563\n",
      "(--> new model saved @ epoch 6000)\n",
      "epoch 7000, training loss 0.06658344715833664, validation loss 0.10653237253427505\n",
      "epoch 8000, training loss 0.06992597877979279, validation loss 0.10637600719928741\n",
      "(--> new model saved @ epoch 8000)\n",
      "epoch 9000, training loss 0.06849543750286102, validation loss 0.10637988150119781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-616e62139b81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcurrent_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m models, step_sizes, mse_list, idx_lowest = find_best_timestep(train_dict[str(current_size)], \n\u001b[0m\u001b[0;32m      3\u001b[0m                                                               \u001b[0mval_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                               \u001b[0mval_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmake_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                              start_k=5, largest_k = 6, dont_train = False)\n",
      "\u001b[1;32m<ipython-input-7-7fe9c937117b>\u001b[0m in \u001b[0;36mfind_best_timestep\u001b[1;34m(train_data, val_data, test_data, current_size, start_k, largest_k, dt, n_forward, noise, make_new, dont_train, lr, max_epochs, batch_size, threshold, criterion, model_dir, i, j)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mstep_sizes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         model_time = train_one_timestep(step_size, train_data, val_data, test_data, current_size, \n\u001b[0m\u001b[0;32m    127\u001b[0m                                         make_new = make_new, dont_train = dont_train,i=i, j=j)\n\u001b[0;32m    128\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-7fe9c937117b>\u001b[0m in \u001b[0;36mtrain_one_timestep\u001b[1;34m(step_size, train_data, val_data, test_data, current_size, dt, n_forward, noise, make_new, dont_train, lr, max_epochs, batch_size, threshold, model_dir, i, j)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     model_time.train_net(dataset, max_epoch=max_epochs, batch_size=batch_size, lr=lr,\n\u001b[0m\u001b[0;32m     59\u001b[0m                     model_path=model_path_this,threshold= threshold)\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-ea660687adbf>\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(self, dataset, max_epoch, batch_size, w, lr, model_path, threshold)\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;31m# =================== backward ====================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;31m# =================== log =========================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "current_size = 1\n",
    "models, step_sizes, mse_list, idx_lowest = find_best_timestep(train_dict[str(current_size)], \n",
    "                                                              val_dict[str(current_size)], \n",
    "                                                              val_dict[str(current_size)], current_size,model_dir=model_dir, make_new = True,#, \n",
    "                                                             start_k=5, largest_k = 6, dont_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================\n",
    "def plot_lowest_error(data, model):\n",
    "    \"\"\"\n",
    "    Plot data at model, idx\n",
    "    \n",
    "    inputs:\n",
    "        data: tensor of shape (n_points, n_timesteps, dim, dim)\n",
    "        model: Resnet model to predict on \n",
    "    outputs:\n",
    "        No returned values, but graph shown\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    data  = torch.flatten(data, 2,3)\n",
    "    _, total_steps, _ = data.shape\n",
    "    y_preds = model.uni_scale_forecast(torch.tensor(data[:,0,:]).float(), n_steps=total_steps-1)\n",
    "    plt.plot(y_preds[0,:,0], label = \"Predicted\")\n",
    "    plt.plot(data[0,1:,0], label = \"Truth\")\n",
    "    plt.ylim([-.1, 1.1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#====================================================================================\n",
    "\n",
    "print(step_sizes[idx_lowest])    \n",
    "print(step_sizes, mse_list)\n",
    "plot_lowest_error(val_dict[str(current_size)], models[idx_lowest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================\n",
    "def find_error_4(data, model, truth_data, tol = 1e-5):\n",
    "    \"\"\"\n",
    "    Find error over the 4 squares \n",
    "    \n",
    "    inputs:\n",
    "        data: tensor of size (n_points, n_timesteps, dim, dim) to be predicted or size (n_points, n_timesteps)\n",
    "        model: Resnet object to predict data on\n",
    "        truth_data: tensor of size (n_points, n_timesteps, dim_larger, dim_larger) compared on \n",
    "        tol = 1e-5: tolerance level to mark points as resolved or not\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "        \n",
    "    outputs:\n",
    "        resolved: boolean whether complete area is resolved or not\n",
    "        loss: array of floats for size (dim, dim) with mse of each square\n",
    "        unresolved: array of booleans, whether that part is resolved or not. (1 unresolved, 0 resolved)\n",
    "    \"\"\"\n",
    "    if(len(data.shape))==2:\n",
    "        data = data.unsqueeze(2).unsqueeze(3)\n",
    "    assert len(data.shape) == 4\n",
    "    n_points, n_timesteps, dim, _ = data.shape\n",
    "    data  = torch.flatten(data, 2,3)\n",
    "    y_preds = model.uni_scale_forecast(torch.tensor(data[:,0,:]).float(), n_steps=n_timesteps-1).reshape(( n_points, n_timesteps-1, dim,dim))\n",
    "    \n",
    "    _,_, truth_dim, _ = truth_data.shape\n",
    "    assert truth_dim >= dim\n",
    "    \n",
    "    loss = mse(y_preds, truth_data[:,1:])\n",
    "    \n",
    "    resolved =  loss.max() <= tol\n",
    "    unresolved_array = torch.tensor(loss <= tol)\n",
    "    \n",
    "    return resolved, loss, 1-unresolved_array.float()\n",
    "\n",
    "\n",
    "\n",
    "#====================================================================================    \n",
    "    \n",
    "def mse(data1, data2):\n",
    "    \"\"\"\n",
    "    Finds Mean Squared Error between data1 and data2\n",
    "    \n",
    "    inputs:\n",
    "        data1: tensor of shape (n_points, n_timestep, dim1, dim1)\n",
    "        data2: tensor of shape (n_points, n_timestep, dim2, dim2)\n",
    "        \n",
    "    output:\n",
    "        mse: array of size (min_dim, min_dim) with mse \n",
    "    \n",
    "    \"\"\"\n",
    "    #find bigger dim\n",
    "    size1 = data1.shape[-1]\n",
    "    size2 = data2.shape[-1]\n",
    "    size_max = max(size1, size2)\n",
    "    \n",
    "    #grow to save sizes and find mse\n",
    "    mse = np.mean((grow(data1, size_max) - grow(data2, size_max))**2, axis = (0, 1))\n",
    "    return mse\n",
    "#====================================================================================\n",
    "    \n",
    "def grow(data, dim_full=128):\n",
    "    '''\n",
    "    Grow tensor from any size to a bigger size\n",
    "    inputs: \n",
    "        data: tensor to grow, size (n_points, n_timesteps, dim_small, dim_small)\n",
    "        dim_full = 128: int of size to grow data to\n",
    "\n",
    "    outputs:\n",
    "        data_full: tensor size (n_points, n_timesteps, size_full, size_full)\n",
    "    '''\n",
    "    n_points, n_timesteps, dim_small, _ = data.shape \n",
    "    assert dim_full % dim_small == 0 #need small to be multiple of full\n",
    "\n",
    "    divide = dim_full // dim_small\n",
    "\n",
    "    data_full = np.zeros((n_points, n_timesteps, dim_full,dim_full))\n",
    "    for i in range(dim_small):\n",
    "        for j in range(dim_small):\n",
    "            repeated = np.repeat(np.repeat(data[:,:,i,j].reshape(n_points,n_timesteps,1,1), divide, axis = 2), divide, axis = 3)\n",
    "            data_full[:,:,i*divide:(i+1)*divide, j*divide:(j+1)*divide] = repeated\n",
    "    return data_full\n",
    "#====================================================================================\n",
    "\n",
    "\n",
    "resolved, loss, unresolved_list = find_error_4(val_dict['1'], models[idx_lowest], val_dict['2'])\n",
    "print(loss.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unresolved_dict[str(current_size)] = torch.tensor(unresolved_list)\n",
    "\n",
    "print(unresolved_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_train_data = unresolved_list * train_dict[str(current_size*2)]\n",
    "print(next_train_data.shape)\n",
    "plt.imshow(next_train_data[0,0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keep.append(models[idx_lowest])\n",
    "model_used_dict['1'] = [[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================\n",
    "def find_error_1(data, model, tol = 1e-5):\n",
    "    \"\"\"\n",
    "    Find error over the 1 square\n",
    "    \n",
    "    inputs:\n",
    "        data: tensor of size (n_points, n_timesteps, dim, dim) to be predicted\n",
    "        model: Resnet object to predict data on\n",
    "        tol = 1e-5: tolerance level to mark points as resolved or not\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "        \n",
    "    outputs:\n",
    "        loss: float of mse\n",
    "        resolved: boolean whether resolved or not\n",
    "    \"\"\"\n",
    "    n_points, n_timesteps  = data.shape\n",
    "    dim = 1\n",
    "    data_input  = data.unsqueeze(2)\n",
    "    y_preds = model.uni_scale_forecast(torch.tensor(data_input[:,0,:]).float(), n_steps=n_timesteps-1).reshape(( n_points, n_timesteps-1, dim,dim))\n",
    "    data1 = data[:,1:]\n",
    "    data2 = y_preds[:,:,0,0]\n",
    "#     print()\n",
    "    loss = torch.mean((data1-data2)**2)#mse(y_preds, data[:,1:])\n",
    "    \n",
    "#     print(loss)\n",
    "    \n",
    "    return loss, loss <= tol\n",
    "\n",
    "#====================================================================================\n",
    "\n",
    "\n",
    "current_size = 2\n",
    "next_train_data = unresolved_list * train_dict[str(current_size)]\n",
    "\n",
    "model_idx_list = np.ones((current_size, current_size))*(-1) #start with all -1\n",
    "\n",
    "for i in range(current_size):\n",
    "    for j in range(current_size):\n",
    "        data_this = next_train_data[:,:,i,j]\n",
    "        if (torch.min(data_this) == 0) and (torch.max(data_this) == 0):\n",
    "            #don't need to do anything is model is resolved\n",
    "            continue\n",
    "        else:\n",
    "        #see if the error is low enough on already made model\n",
    "            for m, model in enumerate(model_keep):\n",
    "                loss, resolved = find_error_1(data_this, model)\n",
    "                step_size = model.step_size\n",
    "                print(\"loss = \", loss)\n",
    "                print(\"step_size = \", step_size)\n",
    "                if resolved:\n",
    "                    model_idx_list[i,j] == m\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "            if not resolved:\n",
    "                i = 0\n",
    "                j = 1\n",
    "                k = int(np.log2(step_size))\n",
    "                print(\"k = \", k)\n",
    "                print(\"train_dict[str(current_size)][:,:,i,j] shape = \", train_dict[str(current_size)][:,:,i,j].shape)\n",
    "                #if no model good, train new model\n",
    "                models, step_sizes, mse_list, idx_lowest = find_best_timestep(train_dict[str(current_size)][:,:,i,j], \n",
    "                                                              val_dict[str(current_size)][:,:,i,j], \n",
    "                                                              val_dict[str(current_size)][:,:,i,j], current_size,model_dir=model_dir, \n",
    "                                                              i=i, j=j, start_k = max(0,k-1), largest_k = k+2)\n",
    "                \n",
    "                vbnm\n",
    "                resolved, loss, unresolved_list = find_error_4(val_dict[str(current_size)][:,:,i,j], \n",
    "                                                               models[idx_lowest], \n",
    "                                                               val_dict[str(current_size)][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size])\n",
    "                model_keep.append(models[idx_lowest])\n",
    "                model_idx_list[i,j] == len(model_keep) #last model will be the one for this square\n",
    "            \n",
    "#             predicted = model.uni_scale_forecast(torch.tensor(data[:,0,:]).float(), n_steps=n_timesteps-1).reshape((  n_points, n_timesteps-1, dim,dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(step_sizes, mse_list, idx_lowest)\n",
    "resolved, loss, unresolved_list = find_error_4(val_dict[str(current_size)][:,:,i,j], \n",
    "                                                               models[idx_lowest], \n",
    "                                                               val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size])\n",
    "print(loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  models[idx_lowest]\n",
    "print(idx_lowest)\n",
    "n_timesteps = 500\n",
    "n_points = 10\n",
    "dim = 1\n",
    "# plt.plot(model(val_dict[str(current_size)][:,:,i,j].unsqueeze(2).unsqueeze(3))[0,:,0,0].detach().numpy(), label = \"predicted\")\n",
    "print(val_dict[str(current_size)][:,0,i,j].unsqueeze(1).shape)\n",
    "val_data_this = val_dict[str(current_size)][:,0,i,j].unsqueeze(1)\n",
    "predicted = model.uni_scale_forecast(val_data_this, n_steps=n_timesteps-1)\n",
    "print(predicted.shape)\n",
    "predicted_reshape = predicted.reshape((  n_points, n_timesteps-1, dim,dim))\n",
    "plt.plot(predicted_reshape[0,:,0], label = \"predicted\")\n",
    "print(val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size].shape)\n",
    "# plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,0], label = \"Truth\")\n",
    "\n",
    "plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,1], label = \"Truth\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_dict[str(current_size*2)][0,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = (16+32)/2\n",
    "print(step_size)\n",
    "model = train_one_timestep(int(28), train_dict[str(current_size)][:,:,i,j].unsqueeze(2), \n",
    "                           val_dict[str(current_size)][:,:,i,j].unsqueeze(2), \n",
    "                           val_dict[str(current_size)][:,:,i,j].unsqueeze(2), current_size)\n",
    "#                        dt = 1, n_forward = 5, noise=0, make_new = False, dont_train = True, \n",
    "#                        lr = 1e-3, max_epochs = 10000, batch_size = 50,threshold = 1e-4, \n",
    "#                        model_dir = './models/toy2',i=None, j = None):\n",
    "    \n",
    "#     train_dict[str(current_size)][:,:,i,j], \n",
    "#                                                               val_dict[str(current_size)][:,:,i,j], \n",
    "#                                                               val_dict[str(current_size)][:,:,i,j], current_size,model_dir=model_dir, \n",
    "#                                                               i=i, j=j, start_k = max(0,k-1), largest_k = k+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "resolved, loss, unresolved_list = find_error_4(val_dict[str(current_size)][:,:,i,j], \n",
    "                                                               model, \n",
    "                                                               val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  models[idx_lowest]\n",
    "print(idx_lowest)\n",
    "n_timesteps = 500\n",
    "n_points = 10\n",
    "dim = 1\n",
    "# plt.plot(model(val_dict[str(current_size)][:,:,i,j].unsqueeze(2).unsqueeze(3))[0,:,0,0].detach().numpy(), label = \"predicted\")\n",
    "print(val_dict[str(current_size)][:,0,i,j].unsqueeze(1).shape)\n",
    "val_data_this = val_dict[str(current_size)][:,0,i,j].unsqueeze(1)\n",
    "predicted = model.uni_scale_forecast(val_data_this, n_steps=n_timesteps-1)\n",
    "print(predicted.shape)\n",
    "predicted_reshape = predicted.reshape((  n_points, n_timesteps-1, dim,dim))\n",
    "plt.plot(predicted_reshape[0,:,0], label = \"predicted\")\n",
    "print(val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size].shape)\n",
    "# plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,0], label = \"Truth\")\n",
    "\n",
    "plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,1], label = \"Truth\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
