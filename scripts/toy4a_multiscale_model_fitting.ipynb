{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiscale model fitting for Toy3a\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start with initalizing many things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reloaded\n",
      "using new ResNet thing\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "# import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm.notebook import tqdm\n",
    "# import time\n",
    "import math\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "        \n",
    "# import torch_cae_multilevel_V4 as net\n",
    "import ResNet as tnet\n",
    "import utils\n",
    "import training_class as tc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_per_process_memory_fraction(0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda:0\n",
      "i =  0\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  1\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  2\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  3\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  4\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  5\n",
      "Transforming\n",
      "reshape to print\n",
      "dict_keys(['64', '32', '16', '8', '4', '2', '1'])\n",
      "i =  0\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  1\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  2\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  3\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  4\n",
      "Transforming\n",
      "reshape to print\n",
      "i =  5\n",
      "Transforming\n",
      "reshape to print\n",
      "dict_keys(['64', '32', '16', '8', '4', '2', '1'])\n",
      "device =  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# paths\n",
    "data_dir = '../data/toy4a'\n",
    "model_dir = '../model/toy4a'\n",
    "result_dir = '../result/toy4a'\n",
    "\n",
    "obj = tc.training_class(data_dir, model_dir, result_dir,tol=1e-4,n_inputs=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside train_one_timestep\n",
      "Making a new model. Old one deleted. model model_L1_D2_noise0.pt\n",
      "create model ../model/toy4a/model_L1_D2_noise0.pt ...\n",
      "device =  cuda:0\n",
      "data shape =  torch.Size([20, 501, 1, 1])\n",
      "train_data  torch.Size([20, 251, 1])\n",
      "data shape =  torch.Size([10, 501, 1, 1])\n",
      "train_data  torch.Size([10, 251, 1])\n",
      "device =  cuda:0\n",
      "epoch  1000 : train_error:  0.7912312 : val_loss  1.0088267 : min_val_loss  1.0486324\n",
      "epoch  2000 : train_error:  0.30586734 : val_loss  0.3893624 : min_val_loss  0.47216558\n",
      "epoch  3000 : train_error:  0.023003023 : val_loss  0.030425647 : min_val_loss  0.031698838\n",
      "epoch  4000 : train_error:  0.018685598 : val_loss  0.024781097 : min_val_loss  0.024910681\n",
      "epoch  5000 : train_error:  0.018191535 : val_loss  0.024135401 : min_val_loss  0.024181949\n",
      "epoch  6000 : train_error:  0.017678218 : val_loss  0.023351626 : min_val_loss  0.023468776\n",
      "epoch  7000 : train_error:  0.017214961 : val_loss  0.0227802 : min_val_loss  0.022935048\n",
      "epoch  8000 : train_error:  0.016822547 : val_loss  0.02229907 : min_val_loss  0.022363834\n",
      "epoch  9000 : train_error:  0.027323134 : val_loss  0.030440956 : min_val_loss  0.021859953\n",
      "epoch  10000 : train_error:  0.020490654 : val_loss  0.029946016 : min_val_loss  0.021379717\n",
      "epoch  11000 : train_error:  0.01586111 : val_loss  0.021431955 : min_val_loss  0.02085074\n",
      "epoch  12000 : train_error:  0.015387502 : val_loss  0.02047958 : min_val_loss  0.02042307\n",
      "epoch  13000 : train_error:  0.015014726 : val_loss  0.019907208 : min_val_loss  0.019769184\n",
      "epoch  14000 : train_error:  0.014650995 : val_loss  0.019426532 : min_val_loss  0.019553544\n",
      "epoch  15000 : train_error:  0.014306336 : val_loss  0.019004015 : min_val_loss  0.018959338\n",
      "epoch  16000 : train_error:  0.014191373 : val_loss  0.01829838 : min_val_loss  0.018545171\n",
      "epoch  17000 : train_error:  0.013597381 : val_loss  0.018226378 : min_val_loss  0.018040782\n",
      "epoch  18000 : train_error:  0.013214208 : val_loss  0.017522665 : min_val_loss  0.01740615\n",
      "epoch  19000 : train_error:  0.01293913 : val_loss  0.018526072 : min_val_loss  0.01702897\n",
      "epoch  20000 : train_error:  0.012478717 : val_loss  0.016549438 : min_val_loss  0.016502118\n",
      "epoch  21000 : train_error:  0.012104874 : val_loss  0.01604885 : min_val_loss  0.016146408\n",
      "epoch  22000 : train_error:  0.011733071 : val_loss  0.0155599 : min_val_loss  0.015663477\n",
      "epoch  23000 : train_error:  0.011633896 : val_loss  0.014971754 : min_val_loss  0.015104539\n",
      "epoch  24000 : train_error:  0.010966802 : val_loss  0.014552249 : min_val_loss  0.01459227\n",
      "epoch  25000 : train_error:  0.0105753485 : val_loss  0.01403674 : min_val_loss  0.013994475\n",
      "epoch  26000 : train_error:  0.010187359 : val_loss  0.013521179 : min_val_loss  0.013571567\n",
      "epoch  27000 : train_error:  0.01132948 : val_loss  0.016895885 : min_val_loss  0.013047255\n",
      "epoch  28000 : train_error:  0.009614537 : val_loss  0.012566052 : min_val_loss  0.012482183\n",
      "epoch  29000 : train_error:  0.0089286035 : val_loss  0.011867835 : min_val_loss  0.0119627435\n",
      "epoch  30000 : train_error:  0.008540009 : val_loss  0.011189425 : min_val_loss  0.011352193\n",
      "epoch  31000 : train_error:  0.008062378 : val_loss  0.010727696 : min_val_loss  0.010842114\n",
      "epoch  32000 : train_error:  0.00758517 : val_loss  0.010158845 : min_val_loss  0.010296762\n",
      "epoch  33000 : train_error:  0.007082308 : val_loss  0.009550913 : min_val_loss  0.009675276\n",
      "epoch  34000 : train_error:  0.0075650094 : val_loss  0.009897718 : min_val_loss  0.009040825\n",
      "epoch  35000 : train_error:  0.0062531615 : val_loss  0.008450821 : min_val_loss  0.008555717\n",
      "epoch  36000 : train_error:  0.005850926 : val_loss  0.007917326 : min_val_loss  0.007985497\n",
      "epoch  37000 : train_error:  0.0054764566 : val_loss  0.007484521 : min_val_loss  0.00745917\n",
      "epoch  38000 : train_error:  0.006570632 : val_loss  0.009790537 : min_val_loss  0.006940176\n",
      "epoch  39000 : train_error:  0.0047200015 : val_loss  0.0063999104 : min_val_loss  0.00649264\n",
      "epoch  40000 : train_error:  0.0048338007 : val_loss  0.005928543 : min_val_loss  0.0059603485\n",
      "epoch  41000 : train_error:  0.004022689 : val_loss  0.0054587983 : min_val_loss  0.0055445065\n",
      "epoch  42000 : train_error:  0.03120363 : val_loss  0.009395271 : min_val_loss  0.0050724545\n",
      "epoch  43000 : train_error:  0.0034610098 : val_loss  0.004643678 : min_val_loss  0.0046397964\n",
      "epoch  44000 : train_error:  0.004685646 : val_loss  0.0064967326 : min_val_loss  0.004254413\n",
      "epoch  45000 : train_error:  0.0032910886 : val_loss  0.00413185 : min_val_loss  0.003885881\n",
      "epoch  46000 : train_error:  0.01327282 : val_loss  0.0041086692 : min_val_loss  0.0035570276\n",
      "epoch  47000 : train_error:  0.019923622 : val_loss  0.031912774 : min_val_loss  0.0032552425\n",
      "epoch  48000 : train_error:  0.0021913925 : val_loss  0.0029493205 : min_val_loss  0.0029465547\n",
      "epoch  49000 : train_error:  0.0037812865 : val_loss  0.0054758056 : min_val_loss  0.002713517\n",
      "epoch  50000 : train_error:  0.0017960639 : val_loss  0.0024792154 : min_val_loss  0.0025055518\n",
      "epoch  51000 : train_error:  0.0016505824 : val_loss  0.0022650347 : min_val_loss  0.0023024594\n",
      "epoch  52000 : train_error:  0.0014995459 : val_loss  0.0020774906 : min_val_loss  0.002099627\n",
      "epoch  53000 : train_error:  0.0013760659 : val_loss  0.0019134748 : min_val_loss  0.0019346349\n",
      "epoch  54000 : train_error:  0.0012595844 : val_loss  0.0017556273 : min_val_loss  0.0017794541\n",
      "epoch  55000 : train_error:  0.0011590952 : val_loss  0.0016234332 : min_val_loss  0.0016505147\n",
      "epoch  56000 : train_error:  0.0010901347 : val_loss  0.0015224193 : min_val_loss  0.0015370785\n",
      "epoch  57000 : train_error:  0.001025053 : val_loss  0.0014373024 : min_val_loss  0.0014106918\n",
      "epoch  58000 : train_error:  0.0012092039 : val_loss  0.0019335592 : min_val_loss  0.0013250881\n",
      "epoch  59000 : train_error:  0.00088047265 : val_loss  0.0012451124 : min_val_loss  0.00125923\n",
      "epoch  60000 : train_error:  0.00086500944 : val_loss  0.001227421 : min_val_loss  0.0011850998\n",
      "epoch  61000 : train_error:  0.00081201794 : val_loss  0.0011453977 : min_val_loss  0.0011437848\n",
      "epoch  62000 : train_error:  0.04814954 : val_loss  0.034707 : min_val_loss  0.0010834825\n",
      "epoch  63000 : train_error:  0.00072419306 : val_loss  0.0010327398 : min_val_loss  0.0010464573\n",
      "epoch  64000 : train_error:  0.00070578215 : val_loss  0.0010072866 : min_val_loss  0.0010022441\n",
      "epoch  65000 : train_error:  0.03713489 : val_loss  0.041027665 : min_val_loss  0.0009676132\n",
      "epoch  66000 : train_error:  0.000645555 : val_loss  0.00092623953 : min_val_loss  0.0009403105\n",
      "epoch  67000 : train_error:  0.00063403277 : val_loss  0.0009099823 : min_val_loss  0.00090594386\n",
      "epoch  68000 : train_error:  0.0007492191 : val_loss  0.0009430455 : min_val_loss  0.00088050606\n",
      "epoch  69000 : train_error:  0.0006011957 : val_loss  0.0008663689 : min_val_loss  0.00086442\n",
      "epoch  70000 : train_error:  0.0005816781 : val_loss  0.0008371162 : min_val_loss  0.00085546565\n",
      "epoch  71000 : train_error:  0.0005850154 : val_loss  0.0008423057 : min_val_loss  0.0008371162\n",
      "Model finished training at epoch  71000  with loss  0.0008371162\n",
      "inside train_one_timestep\n",
      "Making a new model. Old one deleted. model model_L1_D4_noise0.pt\n",
      "create model ../model/toy4a/model_L1_D4_noise0.pt ...\n",
      "device =  cuda:0\n",
      "data shape =  torch.Size([20, 501, 1, 1])\n",
      "train_data  torch.Size([20, 126, 1])\n",
      "data shape =  torch.Size([10, 501, 1, 1])\n",
      "train_data  torch.Size([10, 126, 1])\n",
      "device =  cuda:0\n",
      "epoch  1000 : train_error:  0.25133872 : val_loss  0.3263314 : min_val_loss  0.36512157\n",
      "epoch  2000 : train_error:  0.072197385 : val_loss  0.09678871 : min_val_loss  0.10309009\n",
      "epoch  3000 : train_error:  0.051894102 : val_loss  0.07054746 : min_val_loss  0.07263301\n",
      "epoch  4000 : train_error:  0.039597966 : val_loss  0.05547342 : min_val_loss  0.056468863\n",
      "epoch  5000 : train_error:  0.033659942 : val_loss  0.048418034 : min_val_loss  0.048097912\n",
      "epoch  6000 : train_error:  0.03037125 : val_loss  0.044544578 : min_val_loss  0.044372465\n",
      "epoch  7000 : train_error:  0.030801311 : val_loss  0.04600843 : min_val_loss  0.04331314\n",
      "epoch  8000 : train_error:  0.040120166 : val_loss  0.054429263 : min_val_loss  0.04248194\n"
     ]
    }
   ],
   "source": [
    "import training_class as tc\n",
    "obj, resolved = tc.train_one_step(obj, 1, verbose=True, make_new = True, start_k=1, largest_k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "print(obj.model_keep)\n",
    "utils.plot_lowest_error(obj.model_keep[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = obj.model_keep[0]\n",
    "y_preds, mse = model.predict_mse()\n",
    "plt.plot(y_preds[0].detach().numpy())\n",
    "plt.plot(model.val_data[0, ::model.step_size, 0, 0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj, resolved = tc.train_next_step(obj, 2, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import training_class as tc\n",
    "obj, resolved = tc.train_next_step(obj, 4, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import training_class as tc\n",
    "obj, resolved = tc.train_next_step(obj, 8, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj.model_used_dict['4'])\n",
    "print(obj.model_used_dict['8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "def interpolate(self,current_size,model):\n",
    "    predicted_this, mse = model.predict_mse()\n",
    "    n_points, n_timesteps = predicted_this.shape\n",
    "    interp = np.zeros(predicted_this.shape)\n",
    "    mse_sum = 0\n",
    "    for i in range(interp.shape[0]):\n",
    "        self.model_keep[1].step_size\n",
    "        x = np.arange(4,n_timesteps+4)*model.step_size#current_size\n",
    "        print(\"step_size = \", model.step_size)\n",
    "        y = predicted_this[i]\n",
    "#         y = np.append()\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        f = interp1d(x, y)\n",
    "        print((min(x), max(x)))\n",
    "        xnew = np.arange(min(x), max(x))#, num=41, endpoint=True)\n",
    "        print(f(xnew).shape)\n",
    "        plt.plot(x, y, 'o', label = \"old\")\n",
    "        plt.plot(xnew, f(xnew), label = \"new\")\n",
    "#         interp[i] = f(xnew)\n",
    "#         plt.plot(np.arange(16,500), obj.val_dict[str(current_size)][i,16:,0,0], label = \"truth\")\n",
    "        plt.plot(obj.val_dict[str(current_size)][i,:,0,0], label = \"truth\")\n",
    "#         plt.semilogy(np.arange(16,500), np.abs(obj.val_dict[str(current_size)][i,16:,0,0] - f(xnew)))\n",
    "        plt.legend()\n",
    "#         plt.xlim([0,100])\n",
    "        plt.show()\n",
    "    \n",
    "        mse_sum += torch.mean((obj.val_dict[str(current_size)][0,116:216,0,0] - f(xnew)[100:200])**2)\n",
    "        print(\"mse = \", torch.mean((obj.val_dict[str(current_size)][0,116:216,0,0] - f(xnew)[100:200])**2))\n",
    "        \n",
    "        \n",
    "    print(\"mse total= \", mse_sum / 10)\n",
    "    return interp\n",
    "    \n",
    "interp = interpolate(obj,4,obj.model_keep[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mse(self, data=None):\n",
    "    n_inputs = 3\n",
    "    \n",
    "    if data is None:\n",
    "        #use data in model if none imported\n",
    "        data = self.val_data[:, ::self.step_size]\n",
    "            \n",
    "    n_points, n_timesteps, _, _ = data.shape\n",
    "    mse_list = np.zeros(n_points)\n",
    "    pred_list_all = torch.ones(data.shape[:(n_inputs-1)])*(-1)\n",
    "    for num in range(n_points):\n",
    "        y_pred = data[num, :n_inputs, 0, 0].float().T\n",
    "        pred = y_pred\n",
    "        \n",
    "        for i in range(n_timesteps-n_inputs):\n",
    "            y_next = self.forward(y_pred)\n",
    "            pred = torch.cat((pred,y_next))\n",
    "            y_next = torch.cat((y_pred[1:], y_next))\n",
    "            \n",
    "            \n",
    "            y_pred = y_next\n",
    "\n",
    "        mse = np.mean((pred.detach().numpy() - data[num].detach().numpy())**2)\n",
    "        mse_list[num] = mse\n",
    "        pred_list_all[num] = pred\n",
    "    return pred_list_all, np.mean(mse_list)\n",
    "\n",
    "\n",
    "model=obj.model_keep[0]\n",
    "y_pred, mse = predict_mse(model)\n",
    "print(mse)\n",
    "print(\"y_pres = \", y_pred.shape)\n",
    "plt.plot(y_pred[0,:].detach().numpy())\n",
    "plt.plot(model.val_data[:, ::model.step_size][0,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_pres = \", y_pred.shape)\n",
    "plt.plot(y_pred[0,:].detach().numpy())\n",
    "plt.plot(model.val_data[:, ::model.step_size][0,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=obj.model_keep[1]\n",
    "num = 0\n",
    "data = model.val_data[:,::model.step_size]\n",
    "print(data.shape)\n",
    "inputs = data[num,:3,0]#, data[num,1:-2,0], data[num,2:-1,0]), axis = 1)\n",
    "# old = inputs[0]\n",
    "print(old)\n",
    "print(inputs.shape)\n",
    "\n",
    "print(inputs[0].float())\n",
    "\n",
    "plt.plot(obj.val_dict['2'][0,:,0,0])\n",
    "plt.plot(np.arange(3)*model.step_size, inputs[0])\n",
    "plt.xlim([0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, current_size):\n",
    "    print(int(self.model_used_dict[str(current_size)][0,0]))\n",
    "    predicted_this, mse = self.model_keep[int(self.model_used_dict[str(current_size)][0,0])].predict_mse()\n",
    "    print(predicted_this.shape)\n",
    "    n_points, n_timesteps = predicted_this.shape\n",
    "    print(n_points)\n",
    "    print(n_timesteps)\n",
    "    predicted = np.zeros((n_points, n_timesteps, current_size, current_size))\n",
    "    print(predicted.shape)\n",
    "    for i in range(current_size):\n",
    "        for j in range(current_size):\n",
    "            print(\"int(self.model_used_dict[str(current_size)][i,j])= \", int(self.model_used_dict[str(current_size)][i,j]))\n",
    "            model = self.model_keep[int(self.model_used_dict[str(current_size)][i][j])]\n",
    "            predicted_this, mse = model.predict_mse()\n",
    "            predicted[:,:,i,j] = predicted_this\n",
    "    return predicted\n",
    "predicted = predict(obj, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted[0,1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_dict['1'].shape)\n",
    "plt.plot(val_dict['1'][0,:,0,0], label = '1')\n",
    "plt.plot(val_dict['2'][0,:,0,0], label = '2')\n",
    "# plt.ylim([0,1])\n",
    "mse = torch.mean((val_dict['2'][:,:,0,0] - val_dict['1'][:,:,0,0])**2)\n",
    "print(mse)\n",
    "plt.plot(train_dict['4'][0,:,0,0], label = '4')\n",
    "plt.legend()\n",
    "# plt.plot(train_dict['8'][0,:,0,0])\n",
    "# plt.plot(train_dict['16'][0,:,0,0])\n",
    "# plt.plot(train_dict['32'][0,:,0,0])\n",
    "# plt.plot(train_dict['64'][0,:,0,0])\n",
    "# plt.plot(train_dict['128'][0,:,0,0])\n",
    "# plt.plot(np.cos(np.arange(500)/32*np.pi)/4+.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "print(val_dict['1'].shape)\n",
    "resolved, loss, unresolved_list = utils.find_error_4(val_dict['1'][:10], models[idx_lowest], val_dict['2'][:10], plot = True,tol=0.0003)\n",
    "print(loss.shape)\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log10(loss))\n",
    "plt.title(\"log loss after 1 iteration \")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(models[idx_lowest](val_dict['1']).shape)\n",
    "model = models[idx_lowest]\n",
    "y_preds, mse_avg = model.predict_mse()\n",
    "print(mse_avg)\n",
    "print(model.step_size)\n",
    "# print(utils.mse(y_preds, val_dict['128'][:,::8,0,0]))\n",
    "losses = np.zeros((64,64))\n",
    "for i in range(64):\n",
    "    print(i)\n",
    "    for j in range(64):\n",
    "        truth_with_step_size = val_dict['64'][:,::8,i,j]\n",
    "        loss = utils.mse(y_preds, truth_with_step_size[:, :-3])\n",
    "        losses[i,j] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses)\n",
    "print(np.mean(losses))\n",
    "plt.imshow(losses)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_dict['2'][0,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unresolved_dict[str(current_size)] = torch.tensor(unresolved_list)\n",
    "\n",
    "print(unresolved_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_size = 1\n",
    "next_train_data = unresolved_list * train_dict[str(current_size*2)]\n",
    "print(next_train_data.shape)\n",
    "plt.imshow(next_train_data[0,0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keep = [models[idx_lowest]]\n",
    "model_used_dict[str(current_size)] = [[0]]\n",
    "\n",
    "print(model_used_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "current_size = 2\n",
    "next_train_data = unresolved_list * train_dict[str(current_size)]\n",
    "\n",
    "model_idx_list = np.ones((current_size, current_size))*(-1) #start with all -1\n",
    "\n",
    "for i in range(current_size):\n",
    "    for j in range(current_size):\n",
    "        print(\"i = \", i, \": j = \", j)\n",
    "        data_this = next_train_data[:,:,i,j]\n",
    "        if (torch.min(data_this) == 0) and (torch.max(data_this) == 0):\n",
    "            print(\"zero, no need to train\")\n",
    "            #don't need to do anything is model is resolved\n",
    "            continue\n",
    "        else:\n",
    "        #see if the error is low enough on already made model\n",
    "            for m, model in enumerate(model_keep):\n",
    "                loss, resolved = utils.find_error_1(data_this, model,tol=0.0003)\n",
    "                step_size = model.step_size\n",
    "                print(\"model \", m, \" has loss = \", loss)\n",
    "                if resolved:\n",
    "                    model_idx_list[i,j] = m\n",
    "                    print(\"Resolved with loss = \", loss, \": model #\", m)\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "            if not resolved:\n",
    "                print(\"not resolved, fitting new model\")\n",
    "                k = int(np.log2(step_size))\n",
    "                #if no model good, train new model\n",
    "                models, step_sizes, mse_list, idx_lowest, n_forward_list = utils.find_best_timestep(train_dict[str(current_size)][:,:,i,j], \n",
    "                                                              val_dict[str(current_size)][:,:,i,j], \n",
    "                                                              val_dict[str(current_size)][:,:,i,j], current_size,model_dir=model_dir,#make_new = True,\n",
    "                                                              i=i, j=j, start_k = 2, largest_k =3)#, dont_train=False)\n",
    "                \n",
    "                model_keep.append(models[idx_lowest])\n",
    "                model_idx_list[i,j] = len(model_keep)-1\n",
    "model_used_dict[str(current_size)] = model_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_idx_list)\n",
    "print(len(model_keep))\n",
    "print(model_used_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "tol = 0.0003\n",
    "#once we have all 4 figured out, need to check the errors on the 2x2 of the 2x2s (the 4x4)\n",
    "unresolved_list_big = np.ones((4,4))*(-1)\n",
    "loss_big = np.ones((4,4))*(-1)\n",
    "all_resolved = True\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        print(model_used_dict['2'][i][j])\n",
    "        model = model_keep[int(model_used_dict['2'][i][j])]\n",
    "        print(model.model_name)\n",
    "        data_next = val_dict['4'][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size]\n",
    "        resolved, loss, unresolved_list = utils.find_error_4(val_dict['2'][i,j], model, data_next,plot = True, tol=tol)\n",
    "        unresolved_list_big[i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size] = unresolved_list\n",
    "        loss_big[i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size] = loss\n",
    "        if not resolved:\n",
    "            all_resolved = False\n",
    "        print(loss)\n",
    "        print(unresolved_list)\n",
    "print(\"all_resolved = \", all_resolved)\n",
    "print(\"unresolved_list_big = \", unresolved_list_big)\n",
    "print(\"loss_big = \", loss_big)\n",
    "plt.imshow(np.log10(loss_big),cmap='Greys')\n",
    "plt.colorbar()\n",
    "plt.title(\"log(loss)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing next refine, should be perfect here. \n",
    "import utils\n",
    "\n",
    "\n",
    "current_size = 4\n",
    "print(\"unresolved_list = \", unresolved_list)\n",
    "next_train_data = torch.tensor(unresolved_list_big) * train_dict[str(current_size)]\n",
    "\n",
    "model_idx_list = np.ones((current_size, current_size))*(-1) #start with all -1\n",
    "\n",
    "for i in range(current_size):\n",
    "    for j in range(current_size):\n",
    "        print(\"i = \", i, \": j = \", j)\n",
    "        data_this = next_train_data[:,:,i,j]\n",
    "        if (torch.min(data_this) == 0) and (torch.max(data_this) == 0):\n",
    "            print(\"zero, no need to train\")\n",
    "            #don't need to do anything is model is resolved\n",
    "            continue\n",
    "        else:\n",
    "        #see if the error is low enough on already made model\n",
    "            for m, model in enumerate(model_keep):\n",
    "                loss, resolved = utils.find_error_1(data_this, model)\n",
    "                step_size = model.step_size\n",
    "                print(\"model \", m, \" has loss = \", loss)\n",
    "                if resolved:\n",
    "                    model_idx_list[i,j] = m\n",
    "                    print(\"Resolved with loss = \", loss, \": model #\", m)\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "            if not resolved:\n",
    "                print(\"not resolved, fitting new model\")\n",
    "                k = int(np.log2(step_size))\n",
    "                #if no model good, train new model\n",
    "                models, step_sizes, mse_list, idx_lowest, n_forward_list = utils.find_best_timestep(train_dict[str(current_size)][:,:,i,j], \n",
    "                                                              val_dict[str(current_size)][:,:,i,j], \n",
    "                                                              val_dict[str(current_size)][:,:,i,j], current_size,model_dir=model_dir,#make_new = True,\n",
    "                                                              i=i, j=j, start_k = max(0,k-1), largest_k = k+2)#, dont_train=False)\n",
    "                \n",
    "                model_keep.append(models[idx_lowest])\n",
    "                model_idx_list[i,j] = len(model_keep)-1\n",
    "model_used_dict[str(current_size)] = model_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_idx_list)\n",
    "print(len(model_keep))\n",
    "print(model_used_dict)\n",
    "\n",
    "import utils\n",
    "tol = 2.5e-2\n",
    "#once we have all 4 figured out, need to check the errors on the 2x2 of the 2x2s (the 4x4)\n",
    "unresolved_list_big = np.ones((current_size, current_size))*(-1)\n",
    "all_resolved = True\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "        print(model_used_dict[str(current_size)][i][j])\n",
    "        model = model_keep[int(model_used_dict[str(current_size)][i][j])]\n",
    "        print(model.model_name)\n",
    "        data_next = val_dict[str(current_size)][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size]\n",
    "        print(\"data next shape = \", data_next.shape)\n",
    "        resolved, loss, unresolved_list = utils.find_error_4(val_dict[str(current_size)][i,j], model, data_next,plot = True, tol=tol)\n",
    "        unresolved_list_big[i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size] = unresolved_list\n",
    "        if not resolved:\n",
    "            all_resolved = False\n",
    "        print(loss)\n",
    "        print(\"unresolved_list= \", unresolved_list)\n",
    "print(\"all_resolved = \", all_resolved)\n",
    "print(\"unresolved_list_big = \", unresolved_list_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "model_slow = model_keep[3]\n",
    "data = val_dict['2'][:,:, 1,1]\n",
    "utils.find_error_1(data, model_slow, tol=2e-2, plot=True, title=\"Slow timescale\")\n",
    "\n",
    "model_slow = model_keep[0]\n",
    "data = val_dict['1'][:,:, 0,0]\n",
    "utils.find_error_1(data, model_slow, tol=2e-2, plot=True, title=\"step 1\")\n",
    "\n",
    "\n",
    "model_slow = model_keep[1]\n",
    "data = val_dict['2'][:,:, 0,0]\n",
    "utils.find_error_1(data, model_slow, tol=2e-2, plot=True, title=\"step 2 on split block\")\n",
    "\n",
    "model_fast = model_keep[6]\n",
    "data = val_dict['4'][:,:, 1,1]\n",
    "utils.find_error_1(data, model_fast, tol=2e-2, plot=True, title = \"Fast timescale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(step_sizes, mse_list, idx_lowest)\n",
    "resolved, loss, unresolved_list = utils.find_error_4(val_dict[str(current_size)][:,:,i,j], \n",
    "                                                               models[idx_lowest], \n",
    "                                                               val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size])\n",
    "print(loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  models[idx_lowest]\n",
    "print(idx_lowest)\n",
    "n_timesteps = 500\n",
    "n_points = 10\n",
    "dim = 1\n",
    "# plt.plot(model(val_dict[str(current_size)][:,:,i,j].unsqueeze(2).unsqueeze(3))[0,:,0,0].detach().numpy(), label = \"predicted\")\n",
    "print(val_dict[str(current_size)][:,0,i,j].unsqueeze(1).shape)\n",
    "val_data_this = val_dict[str(current_size)][:,0,i,j].unsqueeze(1)\n",
    "predicted = model.uni_scale_forecast(val_data_this, n_steps=n_timesteps-1)\n",
    "print(predicted.shape)\n",
    "predicted_reshape = predicted.reshape((  n_points, n_timesteps-1, dim,dim))\n",
    "plt.plot(predicted_reshape[0,:,0], label = \"predicted\")\n",
    "print(val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size].shape)\n",
    "# plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,0], label = \"Truth\")\n",
    "\n",
    "plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,1], label = \"Truth\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_dict[str(current_size*2)][0,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = (16+32)/2\n",
    "print(step_size)\n",
    "model = train_one_timestep(int(28), train_dict[str(current_size)][:,:,i,j].unsqueeze(2), \n",
    "                           val_dict[str(current_size)][:,:,i,j].unsqueeze(2), \n",
    "                           val_dict[str(current_size)][:,:,i,j].unsqueeze(2), current_size)\n",
    "#                        dt = 1, n_forward = 5, noise=0, make_new = False, dont_train = True, \n",
    "#                        lr = 1e-3, max_epochs = 10000, batch_size = 50,threshold = 1e-4, \n",
    "#                        model_dir = './models/toy2',i=None, j = None):\n",
    "    \n",
    "#     train_dict[str(current_size)][:,:,i,j], \n",
    "#                                                               val_dict[str(current_size)][:,:,i,j], \n",
    "#                                                               val_dict[str(current_size)][:,:,i,j], current_size,model_dir=model_dir, \n",
    "#                                                               i=i, j=j, start_k = max(0,k-1), largest_k = k+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "resolved, loss, unresolved_list = find_error_4(val_dict[str(current_size)][:,:,i,j], \n",
    "                                                               model, \n",
    "                                                               val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, j*current_size:(j+1)*current_size])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  models[idx_lowest]\n",
    "print(idx_lowest)\n",
    "n_timesteps = 500\n",
    "n_points = 10\n",
    "dim = 1\n",
    "# plt.plot(model(val_dict[str(current_size)][:,:,i,j].unsqueeze(2).unsqueeze(3))[0,:,0,0].detach().numpy(), label = \"predicted\")\n",
    "print(val_dict[str(current_size)][:,0,i,j].unsqueeze(1).shape)\n",
    "val_data_this = val_dict[str(current_size)][:,0,i,j].unsqueeze(1)\n",
    "predicted = model.uni_scale_forecast(val_data_this, n_steps=n_timesteps-1)\n",
    "print(predicted.shape)\n",
    "predicted_reshape = predicted.reshape((  n_points, n_timesteps-1, dim,dim))\n",
    "plt.plot(predicted_reshape[0,:,0], label = \"predicted\")\n",
    "print(val_dict[str(current_size*2)][:,:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size].shape)\n",
    "# plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,0], label = \"Truth\")\n",
    "\n",
    "plt.plot(val_dict[str(current_size*2)][:,1:, i*current_size:(i+1)*current_size, i*current_size:(i+1)*current_size][0,:,0,1], label = \"Truth\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
